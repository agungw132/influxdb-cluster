{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install telegraf at the first server\n",
    "wget https://dl.influxdata.com/telegraf/releases/telegraf_1.7.2-1_amd64.deb\n",
    "sudo dpkg -i telegraf_1.7.2-1_amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec -it influx-cluster-1 telegraf -sample-config -input-filter cpu:mem -output-filter influxdb > telegraf.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Telegraf Configuration\r\n",
      "#\r\n",
      "# Telegraf is entirely plugin driven. All metrics are gathered from the\r\n",
      "# declared inputs, and sent to the declared outputs.\r\n",
      "#\r\n",
      "# Plugins must be declared in here to be active.\r\n",
      "# To deactivate a plugin, comment out the name and any variables.\r\n",
      "#\r\n",
      "# Use 'telegraf -config telegraf.conf -test' to see what metrics a config\r\n",
      "# file would generate.\r\n",
      "#\r\n",
      "# Environment variables can be used anywhere in this config file, simply prepend\r\n",
      "# them with $. For strings the variable must be within quotes (ie, \"$STR_VAR\"),\r\n",
      "# for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)\r\n",
      "\r\n",
      "\r\n",
      "# Global tags can be specified here in key=\"value\" format.\r\n",
      "[global_tags]\r\n",
      "  # dc = \"us-east-1\" # will tag all metrics with dc=us-east-1\r\n",
      "  # rack = \"1a\"\r\n",
      "  ## Environment variables can be used as tags, and throughout the config file\r\n",
      "  # user = \"$USER\"\r\n",
      "\r\n",
      "\r\n",
      "# Configuration for telegraf agent\r\n",
      "[agent]\r\n",
      "  ## Default data collection interval for all inputs\r\n",
      "  interval = \"10s\"\r\n",
      "  ## Rounds collection interval to 'interval'\r\n",
      "  ## ie, if interval=\"10s\" then always collect on :00, :10, :20, etc.\r\n",
      "  round_interval = true\r\n",
      "\r\n",
      "  ## Telegraf will send metrics to outputs in batches of at most\r\n",
      "  ## metric_batch_size metrics.\r\n",
      "  ## This controls the size of writes that Telegraf sends to output plugins.\r\n",
      "  metric_batch_size = 1000\r\n",
      "\r\n",
      "  ## For failed writes, telegraf will cache metric_buffer_limit metrics for each\r\n",
      "  ## output, and will flush this buffer on a successful write. Oldest metrics\r\n",
      "  ## are dropped first when this buffer fills.\r\n",
      "  ## This buffer only fills when writes fail to output plugin(s).\r\n",
      "  metric_buffer_limit = 10000\r\n",
      "\r\n",
      "  ## Collection jitter is used to jitter the collection by a random amount.\r\n",
      "  ## Each plugin will sleep for a random time within jitter before collecting.\r\n",
      "  ## This can be used to avoid many plugins querying things like sysfs at the\r\n",
      "  ## same time, which can have a measurable effect on the system.\r\n",
      "  collection_jitter = \"0s\"\r\n",
      "\r\n",
      "  ## Default flushing interval for all outputs. You shouldn't set this below\r\n",
      "  ## interval. Maximum flush_interval will be flush_interval + flush_jitter\r\n",
      "  flush_interval = \"10s\"\r\n",
      "  ## Jitter the flush interval by a random amount. This is primarily to avoid\r\n",
      "  ## large write spikes for users running a large number of telegraf instances.\r\n",
      "  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s\r\n",
      "  flush_jitter = \"0s\"\r\n",
      "\r\n",
      "  ## By default or when set to \"0s\", precision will be set to the same\r\n",
      "  ## timestamp order as the collection interval, with the maximum being 1s.\r\n",
      "  ##   ie, when interval = \"10s\", precision will be \"1s\"\r\n",
      "  ##       when interval = \"250ms\", precision will be \"1ms\"\r\n",
      "  ## Precision will NOT be used for service inputs. It is up to each individual\r\n",
      "  ## service input to set the timestamp at the appropriate precision.\r\n",
      "  ## Valid time units are \"ns\", \"us\" (or \"Âµs\"), \"ms\", \"s\".\r\n",
      "  precision = \"\"\r\n",
      "\r\n",
      "  ## Logging configuration:\r\n",
      "  ## Run telegraf with debug log messages.\r\n",
      "  debug = false\r\n",
      "  ## Run telegraf in quiet mode (error log messages only).\r\n",
      "  quiet = false\r\n",
      "  ## Specify the log file name. The empty string means to log to stderr.\r\n",
      "  logfile = \"\"\r\n",
      "\r\n",
      "  ## Override default hostname, if empty use os.Hostname()\r\n",
      "  hostname = \"\"\r\n",
      "  ## If set to true, do no set the \"host\" tag in the telegraf agent.\r\n",
      "  omit_hostname = false\r\n",
      "\r\n",
      "\r\n",
      "###############################################################################\r\n",
      "#                            OUTPUT PLUGINS                                   #\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "# Configuration for sending metrics to InfluxDB\r\n",
      "[[outputs.influxdb]]\r\n",
      "  ## The full HTTP or UDP URL for your InfluxDB instance.\r\n",
      "  ##\r\n",
      "  ## Multiple URLs can be specified for a single cluster, only ONE of the\r\n",
      "  ## urls will be written to each interval.\r\n",
      "  # urls = [\"unix:///var/run/influxdb.sock\"]\r\n",
      "  # urls = [\"udp://127.0.0.1:8089\"]\r\n",
      "  # urls = [\"http://127.0.0.1:8086\"]\r\n",
      "\r\n",
      "  ## The target database for metrics; will be created as needed.\r\n",
      "  # database = \"telegraf\"\r\n",
      "\r\n",
      "  ## If true, no CREATE DATABASE queries will be sent.  Set to true when using\r\n",
      "  ## Telegraf with a user without permissions to create databases or when the\r\n",
      "  ## database already exists.\r\n",
      "  # skip_database_creation = false\r\n",
      "\r\n",
      "  ## Name of existing retention policy to write to.  Empty string writes to\r\n",
      "  ## the default retention policy.  Only takes effect when using HTTP.\r\n",
      "  # retention_policy = \"\"\r\n",
      "\r\n",
      "  ## Write consistency (clusters only), can be: \"any\", \"one\", \"quorum\", \"all\".\r\n",
      "  ## Only takes effect when using HTTP.\r\n",
      "  # write_consistency = \"any\"\r\n",
      "\r\n",
      "  ## Timeout for HTTP messages.\r\n",
      "  # timeout = \"5s\"\r\n",
      "\r\n",
      "  ## HTTP Basic Auth\r\n",
      "  # username = \"telegraf\"\r\n",
      "  # password = \"metricsmetricsmetricsmetrics\"\r\n",
      "\r\n",
      "  ## HTTP User-Agent\r\n",
      "  # user_agent = \"telegraf\"\r\n",
      "\r\n",
      "  ## UDP payload size is the maximum packet size to send.\r\n",
      "  # udp_payload = 512\r\n",
      "\r\n",
      "  ## Optional TLS Config for use on HTTP connections.\r\n",
      "  # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "  # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "  # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "  ## Use TLS but skip chain & host verification\r\n",
      "  # insecure_skip_verify = false\r\n",
      "\r\n",
      "  ## HTTP Proxy override, if unset values the standard proxy environment\r\n",
      "  ## variables are consulted to determine which proxy, if any, should be used.\r\n",
      "  # http_proxy = \"http://corporate.proxy:3128\"\r\n",
      "\r\n",
      "  ## Additional HTTP headers\r\n",
      "  # http_headers = {\"X-Special-Header\" = \"Special-Value\"}\r\n",
      "\r\n",
      "  ## HTTP Content-Encoding for write request body, can be set to \"gzip\" to\r\n",
      "  ## compress body or \"identity\" to apply no encoding.\r\n",
      "  # content_encoding = \"identity\"\r\n",
      "\r\n",
      "  ## When true, Telegraf will output unsigned integers as unsigned values,\r\n",
      "  ## i.e.: \"42u\".  You will need a version of InfluxDB supporting unsigned\r\n",
      "  ## integer values.  Enabling this option will result in field type errors if\r\n",
      "  ## existing data has been written.\r\n",
      "  # influx_uint_support = false\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for Amon Server to send metrics to.\r\n",
      "# [[outputs.amon]]\r\n",
      "#   ## Amon Server Key\r\n",
      "#   server_key = \"my-server-key\" # required.\r\n",
      "#\r\n",
      "#   ## Amon Instance URL\r\n",
      "#   amon_instance = \"https://youramoninstance\" # required\r\n",
      "#\r\n",
      "#   ## Connection timeout.\r\n",
      "#   # timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Publishes metrics to an AMQP broker\r\n",
      "# [[outputs.amqp]]\r\n",
      "#   ## Broker to publish to.\r\n",
      "#   ##   deprecated in 1.7; use the brokers option\r\n",
      "#   # url = \"amqp://localhost:5672/influxdb\"\r\n",
      "#\r\n",
      "#   ## Brokers to publish to.  If multiple brokers are specified a random broker\r\n",
      "#   ## will be selected anytime a connection is established.  This can be\r\n",
      "#   ## helpful for load balancing when not using a dedicated load balancer.\r\n",
      "#   brokers = [\"amqp://localhost:5672/influxdb\"]\r\n",
      "#\r\n",
      "#   ## Maximum messages to send over a connection.  Once this is reached, the\r\n",
      "#   ## connection is closed and a new connection is made.  This can be helpful for\r\n",
      "#   ## load balancing when not using a dedicated load balancer.\r\n",
      "#   # max_messages = 0\r\n",
      "#\r\n",
      "#   ## Exchange to declare and publish to.\r\n",
      "#   exchange = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## Exchange type; common types are \"direct\", \"fanout\", \"topic\", \"header\", \"x-consistent-hash\".\r\n",
      "#   # exchange_type = \"topic\"\r\n",
      "#\r\n",
      "#   ## If true, exchange will be passively declared.\r\n",
      "#   # exchange_declare_passive = false\r\n",
      "#\r\n",
      "#   ## If true, exchange will be created as a durable exchange.\r\n",
      "#   # exchange_durable = true\r\n",
      "#\r\n",
      "#   ## Additional exchange arguments.\r\n",
      "#   # exchange_arguments = { }\r\n",
      "#   # exchange_arguments = {\"hash_propery\" = \"timestamp\"}\r\n",
      "#\r\n",
      "#   ## Authentication credentials for the PLAIN auth_method.\r\n",
      "#   # username = \"\"\r\n",
      "#   # password = \"\"\r\n",
      "#\r\n",
      "#   ## Auth method. PLAIN and EXTERNAL are supported\r\n",
      "#   ## Using EXTERNAL requires enabling the rabbitmq_auth_mechanism_ssl plugin as\r\n",
      "#   ## described here: https://www.rabbitmq.com/plugins.html\r\n",
      "#   # auth_method = \"PLAIN\"\r\n",
      "#\r\n",
      "#   ## Metric tag to use as a routing key.\r\n",
      "#   ##   ie, if this tag exists, its value will be used as the routing key\r\n",
      "#   # routing_tag = \"host\"\r\n",
      "#\r\n",
      "#   ## Static routing key.  Used when no routing_tag is set or as a fallback\r\n",
      "#   ## when the tag specified in routing tag is not found.\r\n",
      "#   # routing_key = \"\"\r\n",
      "#   # routing_key = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## Delivery Mode controls if a published message is persistent.\r\n",
      "#   ##   One of \"transient\" or \"persistent\".\r\n",
      "#   # delivery_mode = \"transient\"\r\n",
      "#\r\n",
      "#   ## InfluxDB database added as a message header.\r\n",
      "#   ##   deprecated in 1.7; use the headers option\r\n",
      "#   # database = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## InfluxDB retention policy added as a message header\r\n",
      "#   ##   deprecated in 1.7; use the headers option\r\n",
      "#   # retention_policy = \"default\"\r\n",
      "#\r\n",
      "#   ## Static headers added to each published message.\r\n",
      "#   # headers = { }\r\n",
      "#   # headers = {\"database\" = \"telegraf\", \"retention_policy\" = \"default\"}\r\n",
      "#\r\n",
      "#   ## Connection timeout.  If not provided, will default to 5s.  0s means no\r\n",
      "#   ## timeout (not recommended).\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## If true use batch serialization format instead of line based delimiting.\r\n",
      "#   ## Only applies to data formats which are not line based such as JSON.\r\n",
      "#   ## Recommended to set to true.\r\n",
      "#   # use_batch_format = false\r\n",
      "#\r\n",
      "#   ## Data format to output.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   # data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Send metrics to Azure Application Insights\r\n",
      "# [[outputs.application_insights]]\r\n",
      "#   ## Instrumentation key of the Application Insights resource.\r\n",
      "#   instrumentation_key = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxx\"\r\n",
      "#\r\n",
      "#   ## Timeout for closing (default: 5s).\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Enable additional diagnostic logging.\r\n",
      "#   # enable_diagnosic_logging = false\r\n",
      "#\r\n",
      "#   ## Context Tag Sources add Application Insights context tags to a tag value.\r\n",
      "#   ##\r\n",
      "#   ## For list of allowed context tag keys see:\r\n",
      "#   ## https://github.com/Microsoft/ApplicationInsights-Go/blob/master/appinsights/contracts/contexttagkeys.go\r\n",
      "#   # [outputs.application_insights.context_tag_sources]\r\n",
      "#   #   \"ai.cloud.role\" = \"kubernetes_container_name\"\r\n",
      "#   #   \"ai.cloud.roleInstance\" = \"kubernetes_pod_name\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for AWS CloudWatch output.\r\n",
      "# [[outputs.cloudwatch]]\r\n",
      "#   ## Amazon REGION\r\n",
      "#   region = \"us-east-1\"\r\n",
      "#\r\n",
      "#   ## Amazon Credentials\r\n",
      "#   ## Credentials are loaded in the following order\r\n",
      "#   ## 1) Assumed credentials via STS if role_arn is specified\r\n",
      "#   ## 2) explicit credentials from 'access_key' and 'secret_key'\r\n",
      "#   ## 3) shared profile from 'profile'\r\n",
      "#   ## 4) environment variables\r\n",
      "#   ## 5) shared credentials file\r\n",
      "#   ## 6) EC2 Instance Profile\r\n",
      "#   #access_key = \"\"\r\n",
      "#   #secret_key = \"\"\r\n",
      "#   #token = \"\"\r\n",
      "#   #role_arn = \"\"\r\n",
      "#   #profile = \"\"\r\n",
      "#   #shared_credential_file = \"\"\r\n",
      "#\r\n",
      "#   ## Namespace for the CloudWatch MetricDatums\r\n",
      "#   namespace = \"InfluxData/Telegraf\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for CrateDB to send metrics to.\r\n",
      "# [[outputs.cratedb]]\r\n",
      "#   # A github.com/jackc/pgx connection string.\r\n",
      "#   # See https://godoc.org/github.com/jackc/pgx#ParseDSN\r\n",
      "#   url = \"postgres://user:password@localhost/schema?sslmode=disable\"\r\n",
      "#   # Timeout for all CrateDB queries.\r\n",
      "#   timeout = \"5s\"\r\n",
      "#   # Name of the table to store metrics in.\r\n",
      "#   table = \"metrics\"\r\n",
      "#   # If true, and the metrics table does not exist, create it automatically.\r\n",
      "#   table_create = true\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for DataDog API to send metrics to.\r\n",
      "# [[outputs.datadog]]\r\n",
      "#   ## Datadog API key\r\n",
      "#   apikey = \"my-secret-key\" # required.\r\n",
      "#\r\n",
      "#   ## Connection timeout.\r\n",
      "#   # timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Send metrics to nowhere at all\r\n",
      "# [[outputs.discard]]\r\n",
      "#   # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for Elasticsearch to send metrics to.\r\n",
      "# [[outputs.elasticsearch]]\r\n",
      "#   ## The full HTTP endpoint URL for your Elasticsearch instance\r\n",
      "#   ## Multiple urls can be specified as part of the same cluster,\r\n",
      "#   ## this means that only ONE of the urls will be written to each interval.\r\n",
      "#   urls = [ \"http://node1.es.example.com:9200\" ] # required.\r\n",
      "#   ## Elasticsearch client timeout, defaults to \"5s\" if not set.\r\n",
      "#   timeout = \"5s\"\r\n",
      "#   ## Set to true to ask Elasticsearch a list of all cluster nodes,\r\n",
      "#   ## thus it is not necessary to list all nodes in the urls config option.\r\n",
      "#   enable_sniffer = false\r\n",
      "#   ## Set the interval to check if the Elasticsearch nodes are available\r\n",
      "#   ## Setting to \"0s\" will disable the health check (not recommended in production)\r\n",
      "#   health_check_interval = \"10s\"\r\n",
      "#   ## HTTP basic authentication details (eg. when using Shield)\r\n",
      "#   # username = \"telegraf\"\r\n",
      "#   # password = \"mypassword\"\r\n",
      "#\r\n",
      "#   ## Index Config\r\n",
      "#   ## The target index for metrics (Elasticsearch will create if it not exists).\r\n",
      "#   ## You can use the date specifiers below to create indexes per time frame.\r\n",
      "#   ## The metric timestamp will be used to decide the destination index name\r\n",
      "#   # %Y - year (2016)\r\n",
      "#   # %y - last two digits of year (00..99)\r\n",
      "#   # %m - month (01..12)\r\n",
      "#   # %d - day of month (e.g., 01)\r\n",
      "#   # %H - hour (00..23)\r\n",
      "#   # %V - week of the year (ISO week) (01..53)\r\n",
      "#   ## Additionally, you can specify a tag name using the notation {{tag_name}}\r\n",
      "#   ## which will be used as part of the index name. If the tag does not exist,\r\n",
      "#   ## the default tag value will be used.\r\n",
      "#   # index_name = \"telegraf-{{host}}-%Y.%m.%d\"\r\n",
      "#   # default_tag_value = \"none\"\r\n",
      "#   index_name = \"telegraf-%Y.%m.%d\" # required.\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Template Config\r\n",
      "#   ## Set to true if you want telegraf to manage its index template.\r\n",
      "#   ## If enabled it will create a recommended index template for telegraf indexes\r\n",
      "#   manage_template = true\r\n",
      "#   ## The template name used for telegraf indexes\r\n",
      "#   template_name = \"telegraf\"\r\n",
      "#   ## Set to true if you want telegraf to overwrite an existing template\r\n",
      "#   overwrite_template = false\r\n",
      "\r\n",
      "\r\n",
      "# # Send telegraf metrics to file(s)\r\n",
      "# [[outputs.file]]\r\n",
      "#   ## Files to write to, \"stdout\" is a specially handled file.\r\n",
      "#   files = [\"stdout\", \"/tmp/metrics.out\"]\r\n",
      "#\r\n",
      "#   ## Data format to output.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for Graphite server to send metrics to\r\n",
      "# [[outputs.graphite]]\r\n",
      "#   ## TCP endpoint for your graphite instance.\r\n",
      "#   ## If multiple endpoints are configured, output will be load balanced.\r\n",
      "#   ## Only one of the endpoints will be written to with each iteration.\r\n",
      "#   servers = [\"localhost:2003\"]\r\n",
      "#   ## Prefix metrics name\r\n",
      "#   prefix = \"\"\r\n",
      "#   ## Graphite output template\r\n",
      "#   ## see https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   template = \"host.tags.measurement.field\"\r\n",
      "#\r\n",
      "#   ## Enable Graphite tags support\r\n",
      "#   # graphite_tag_support = false\r\n",
      "#\r\n",
      "#   ## timeout in seconds for the write connection to graphite\r\n",
      "#   timeout = 2\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Send telegraf metrics to graylog(s)\r\n",
      "# [[outputs.graylog]]\r\n",
      "#   ## UDP endpoint for your graylog instance.\r\n",
      "#   servers = [\"127.0.0.1:12201\", \"192.168.1.1:12201\"]\r\n",
      "\r\n",
      "\r\n",
      "# # A plugin that can transmit metrics over HTTP\r\n",
      "# [[outputs.http]]\r\n",
      "#   ## URL is the address to send metrics to\r\n",
      "#   url = \"http://127.0.0.1:8080/metric\"\r\n",
      "#\r\n",
      "#   ## Timeout for HTTP message\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## HTTP method, one of: \"POST\" or \"PUT\"\r\n",
      "#   # method = \"POST\"\r\n",
      "#\r\n",
      "#   ## HTTP Basic Auth credentials\r\n",
      "#   # username = \"username\"\r\n",
      "#   # password = \"pa$$word\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Data format to output.\r\n",
      "#   ## Each data format has it's own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   # data_format = \"influx\"\r\n",
      "#\r\n",
      "#   ## Additional HTTP headers\r\n",
      "#   # [outputs.http.headers]\r\n",
      "#   #   # Should be set manually to \"application/json\" for json data_format\r\n",
      "#   #   Content-Type = \"text/plain; charset=utf-8\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for sending metrics to an Instrumental project\r\n",
      "# [[outputs.instrumental]]\r\n",
      "#   ## Project API Token (required)\r\n",
      "#   api_token = \"API Token\" # required\r\n",
      "#   ## Prefix the metrics with a given name\r\n",
      "#   prefix = \"\"\r\n",
      "#   ## Stats output template (Graphite formatting)\r\n",
      "#   ## see https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#graphite\r\n",
      "#   template = \"host.tags.measurement.field\"\r\n",
      "#   ## Timeout in seconds to connect\r\n",
      "#   timeout = \"2s\"\r\n",
      "#   ## Display Communcation to Instrumental\r\n",
      "#   debug = false\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for the Kafka server to send metrics to\r\n",
      "# [[outputs.kafka]]\r\n",
      "#   ## URLs of kafka brokers\r\n",
      "#   brokers = [\"localhost:9092\"]\r\n",
      "#   ## Kafka topic for producer messages\r\n",
      "#   topic = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## Optional topic suffix configuration.\r\n",
      "#   ## If the section is omitted, no suffix is used.\r\n",
      "#   ## Following topic suffix methods are supported:\r\n",
      "#   ##   measurement - suffix equals to separator + measurement's name\r\n",
      "#   ##   tags        - suffix equals to separator + specified tags' values\r\n",
      "#   ##                 interleaved with separator\r\n",
      "#\r\n",
      "#   ## Suffix equals to \"_\" + measurement name\r\n",
      "#   # [outputs.kafka.topic_suffix]\r\n",
      "#   #   method = \"measurement\"\r\n",
      "#   #   separator = \"_\"\r\n",
      "#\r\n",
      "#   ## Suffix equals to \"__\" + measurement's \"foo\" tag value.\r\n",
      "#   ##   If there's no such a tag, suffix equals to an empty string\r\n",
      "#   # [outputs.kafka.topic_suffix]\r\n",
      "#   #   method = \"tags\"\r\n",
      "#   #   keys = [\"foo\"]\r\n",
      "#   #   separator = \"__\"\r\n",
      "#\r\n",
      "#   ## Suffix equals to \"_\" + measurement's \"foo\" and \"bar\"\r\n",
      "#   ##   tag values, separated by \"_\". If there is no such tags,\r\n",
      "#   ##   their values treated as empty strings.\r\n",
      "#   # [outputs.kafka.topic_suffix]\r\n",
      "#   #   method = \"tags\"\r\n",
      "#   #   keys = [\"foo\", \"bar\"]\r\n",
      "#   #   separator = \"_\"\r\n",
      "#\r\n",
      "#   ## Telegraf tag to use as a routing key\r\n",
      "#   ##  ie, if this tag exists, its value will be used as the routing key\r\n",
      "#   routing_tag = \"host\"\r\n",
      "#\r\n",
      "#   ## CompressionCodec represents the various compression codecs recognized by\r\n",
      "#   ## Kafka in messages.\r\n",
      "#   ##  0 : No compression\r\n",
      "#   ##  1 : Gzip compression\r\n",
      "#   ##  2 : Snappy compression\r\n",
      "#   # compression_codec = 0\r\n",
      "#\r\n",
      "#   ##  RequiredAcks is used in Produce Requests to tell the broker how many\r\n",
      "#   ##  replica acknowledgements it must see before responding\r\n",
      "#   ##   0 : the producer never waits for an acknowledgement from the broker.\r\n",
      "#   ##       This option provides the lowest latency but the weakest durability\r\n",
      "#   ##       guarantees (some data will be lost when a server fails).\r\n",
      "#   ##   1 : the producer gets an acknowledgement after the leader replica has\r\n",
      "#   ##       received the data. This option provides better durability as the\r\n",
      "#   ##       client waits until the server acknowledges the request as successful\r\n",
      "#   ##       (only messages that were written to the now-dead leader but not yet\r\n",
      "#   ##       replicated will be lost).\r\n",
      "#   ##   -1: the producer gets an acknowledgement after all in-sync replicas have\r\n",
      "#   ##       received the data. This option provides the best durability, we\r\n",
      "#   ##       guarantee that no messages will be lost as long as at least one in\r\n",
      "#   ##       sync replica remains.\r\n",
      "#   # required_acks = -1\r\n",
      "#\r\n",
      "#   ## The maximum number of times to retry sending a metric before failing\r\n",
      "#   ## until the next flush.\r\n",
      "#   # max_retry = 3\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Optional SASL Config\r\n",
      "#   # sasl_username = \"kafka\"\r\n",
      "#   # sasl_password = \"secret\"\r\n",
      "#\r\n",
      "#   ## Data format to output.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   # data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for the AWS Kinesis output.\r\n",
      "# [[outputs.kinesis]]\r\n",
      "#   ## Amazon REGION of kinesis endpoint.\r\n",
      "#   region = \"ap-southeast-2\"\r\n",
      "#\r\n",
      "#   ## Amazon Credentials\r\n",
      "#   ## Credentials are loaded in the following order\r\n",
      "#   ## 1) Assumed credentials via STS if role_arn is specified\r\n",
      "#   ## 2) explicit credentials from 'access_key' and 'secret_key'\r\n",
      "#   ## 3) shared profile from 'profile'\r\n",
      "#   ## 4) environment variables\r\n",
      "#   ## 5) shared credentials file\r\n",
      "#   ## 6) EC2 Instance Profile\r\n",
      "#   #access_key = \"\"\r\n",
      "#   #secret_key = \"\"\r\n",
      "#   #token = \"\"\r\n",
      "#   #role_arn = \"\"\r\n",
      "#   #profile = \"\"\r\n",
      "#   #shared_credential_file = \"\"\r\n",
      "#\r\n",
      "#   ## Kinesis StreamName must exist prior to starting telegraf.\r\n",
      "#   streamname = \"StreamName\"\r\n",
      "#   ## DEPRECATED: PartitionKey as used for sharding data.\r\n",
      "#   partitionkey = \"PartitionKey\"\r\n",
      "#   ## DEPRECATED: If set the paritionKey will be a random UUID on every put.\r\n",
      "#   ## This allows for scaling across multiple shards in a stream.\r\n",
      "#   ## This will cause issues with ordering.\r\n",
      "#   use_random_partitionkey = false\r\n",
      "#   ## The partition key can be calculated using one of several methods:\r\n",
      "#   ##\r\n",
      "#   ## Use a static value for all writes:\r\n",
      "#   #  [outputs.kinesis.partition]\r\n",
      "#   #    method = \"static\"\r\n",
      "#   #    key = \"howdy\"\r\n",
      "#   #\r\n",
      "#   ## Use a random partition key on each write:\r\n",
      "#   #  [outputs.kinesis.partition]\r\n",
      "#   #    method = \"random\"\r\n",
      "#   #\r\n",
      "#   ## Use the measurement name as the partition key:\r\n",
      "#   #  [outputs.kinesis.partition]\r\n",
      "#   #    method = \"measurement\"\r\n",
      "#   #\r\n",
      "#   ## Use the value of a tag for all writes, if the tag is not set the empty\r\n",
      "#   ## string will be used:\r\n",
      "#   #  [outputs.kinesis.partition]\r\n",
      "#   #    method = \"tag\"\r\n",
      "#   #    key = \"host\"\r\n",
      "#\r\n",
      "#\r\n",
      "#   ## Data format to output.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "#\r\n",
      "#   ## debug will show upstream aws messages.\r\n",
      "#   debug = false\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for Librato API to send metrics to.\r\n",
      "# [[outputs.librato]]\r\n",
      "#   ## Librator API Docs\r\n",
      "#   ## http://dev.librato.com/v1/metrics-authentication\r\n",
      "#   ## Librato API user\r\n",
      "#   api_user = \"telegraf@influxdb.com\" # required.\r\n",
      "#   ## Librato API token\r\n",
      "#   api_token = \"my-secret-token\" # required.\r\n",
      "#   ## Debug\r\n",
      "#   # debug = false\r\n",
      "#   ## Connection timeout.\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#   ## Output source Template (same as graphite buckets)\r\n",
      "#   ## see https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md#graphite\r\n",
      "#   ## This template is used in librato's source (not metric's name)\r\n",
      "#   template = \"host\"\r\n",
      "#\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for MQTT server to send metrics to\r\n",
      "# [[outputs.mqtt]]\r\n",
      "#   servers = [\"localhost:1883\"] # required.\r\n",
      "#\r\n",
      "#   ## MQTT outputs send metrics to this topic format\r\n",
      "#   ##    \"<topic_prefix>/<hostname>/<pluginname>/\"\r\n",
      "#   ##   ex: prefix/web01.example.com/mem\r\n",
      "#   topic_prefix = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## QoS policy for messages\r\n",
      "#   ##   0 = at most once\r\n",
      "#   ##   1 = at least once\r\n",
      "#   ##   2 = exactly once\r\n",
      "#   # qos = 2\r\n",
      "#\r\n",
      "#   ## username and password to connect MQTT server.\r\n",
      "#   # username = \"telegraf\"\r\n",
      "#   # password = \"metricsmetricsmetricsmetrics\"\r\n",
      "#\r\n",
      "#   ## client ID, if not set a random ID is generated\r\n",
      "#   # client_id = \"\"\r\n",
      "#\r\n",
      "#   ## Timeout for write operations. default: 5s\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## When true, metrics will be sent in one MQTT message per flush.  Otherwise,\r\n",
      "#   ## metrics are written one metric per MQTT message.\r\n",
      "#   # batch = false\r\n",
      "#\r\n",
      "#   ## Data format to output.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Send telegraf measurements to NATS\r\n",
      "# [[outputs.nats]]\r\n",
      "#   ## URLs of NATS servers\r\n",
      "#   servers = [\"nats://localhost:4222\"]\r\n",
      "#   ## Optional credentials\r\n",
      "#   # username = \"\"\r\n",
      "#   # password = \"\"\r\n",
      "#   ## NATS subject for producer messages\r\n",
      "#   subject = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Data format to output.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Send telegraf measurements to NSQD\r\n",
      "# [[outputs.nsq]]\r\n",
      "#   ## Location of nsqd instance listening on TCP\r\n",
      "#   server = \"localhost:4150\"\r\n",
      "#   ## NSQ topic for producer messages\r\n",
      "#   topic = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## Data format to output.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for OpenTSDB server to send metrics to\r\n",
      "# [[outputs.opentsdb]]\r\n",
      "#   ## prefix for metrics keys\r\n",
      "#   prefix = \"my.specific.prefix.\"\r\n",
      "#\r\n",
      "#   ## DNS name of the OpenTSDB server\r\n",
      "#   ## Using \"opentsdb.example.com\" or \"tcp://opentsdb.example.com\" will use the\r\n",
      "#   ## telnet API. \"http://opentsdb.example.com\" will use the Http API.\r\n",
      "#   host = \"opentsdb.example.com\"\r\n",
      "#\r\n",
      "#   ## Port of the OpenTSDB server\r\n",
      "#   port = 4242\r\n",
      "#\r\n",
      "#   ## Number of data points to send to OpenTSDB in Http requests.\r\n",
      "#   ## Not used with telnet API.\r\n",
      "#   httpBatchSize = 50\r\n",
      "#\r\n",
      "#   ## Debug true - Prints OpenTSDB communication\r\n",
      "#   debug = false\r\n",
      "#\r\n",
      "#   ## Separator separates measurement name from field\r\n",
      "#   separator = \"_\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for the Prometheus client to spawn\r\n",
      "# [[outputs.prometheus_client]]\r\n",
      "#   ## Address to listen on\r\n",
      "#   # listen = \":9273\"\r\n",
      "#\r\n",
      "#   ## Use TLS\r\n",
      "#   #tls_cert = \"/etc/ssl/telegraf.crt\"\r\n",
      "#   #tls_key = \"/etc/ssl/telegraf.key\"\r\n",
      "#\r\n",
      "#   ## Use http basic authentication\r\n",
      "#   #basic_username = \"Foo\"\r\n",
      "#   #basic_password = \"Bar\"\r\n",
      "#\r\n",
      "#   ## Interval to expire metrics and not deliver to prometheus, 0 == no expiration\r\n",
      "#   # expiration_interval = \"60s\"\r\n",
      "#\r\n",
      "#   ## Collectors to enable, valid entries are \"gocollector\" and \"process\".\r\n",
      "#   ## If unset, both are enabled.\r\n",
      "#   collectors_exclude = [\"gocollector\", \"process\"]\r\n",
      "#\r\n",
      "#   # Send string metrics as Prometheus labels.\r\n",
      "#   # Unless set to false all string metrics will be sent as labels.\r\n",
      "#   string_as_label = true\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for the Riemann server to send metrics to\r\n",
      "# [[outputs.riemann]]\r\n",
      "#   ## The full TCP or UDP URL of the Riemann server\r\n",
      "#   url = \"tcp://localhost:5555\"\r\n",
      "#\r\n",
      "#   ## Riemann event TTL, floating-point time in seconds.\r\n",
      "#   ## Defines how long that an event is considered valid for in Riemann\r\n",
      "#   # ttl = 30.0\r\n",
      "#\r\n",
      "#   ## Separator to use between measurement and field name in Riemann service name\r\n",
      "#   ## This does not have any effect if 'measurement_as_attribute' is set to 'true'\r\n",
      "#   separator = \"/\"\r\n",
      "#\r\n",
      "#   ## Set measurement name as Riemann attribute 'measurement', instead of prepending it to the Riemann service name\r\n",
      "#   # measurement_as_attribute = false\r\n",
      "#\r\n",
      "#   ## Send string metrics as Riemann event states.\r\n",
      "#   ## Unless enabled all string metrics will be ignored\r\n",
      "#   # string_as_state = false\r\n",
      "#\r\n",
      "#   ## A list of tag keys whose values get sent as Riemann tags.\r\n",
      "#   ## If empty, all Telegraf tag values will be sent as tags\r\n",
      "#   # tag_keys = [\"telegraf\",\"custom_tag\"]\r\n",
      "#\r\n",
      "#   ## Additional Riemann tags to send.\r\n",
      "#   # tags = [\"telegraf-output\"]\r\n",
      "#\r\n",
      "#   ## Description for Riemann event\r\n",
      "#   # description_text = \"metrics collected from telegraf\"\r\n",
      "#\r\n",
      "#   ## Riemann client write timeout, defaults to \"5s\" if not set.\r\n",
      "#   # timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for the Riemann server to send metrics to\r\n",
      "# [[outputs.riemann_legacy]]\r\n",
      "#   ## URL of server\r\n",
      "#   url = \"localhost:5555\"\r\n",
      "#   ## transport protocol to use either tcp or udp\r\n",
      "#   transport = \"tcp\"\r\n",
      "#   ## separator to use between input name and field name in Riemann service name\r\n",
      "#   separator = \" \"\r\n",
      "\r\n",
      "\r\n",
      "# # Generic socket writer capable of handling multiple socket types.\r\n",
      "# [[outputs.socket_writer]]\r\n",
      "#   ## URL to connect to\r\n",
      "#   # address = \"tcp://127.0.0.1:8094\"\r\n",
      "#   # address = \"tcp://example.com:http\"\r\n",
      "#   # address = \"tcp4://127.0.0.1:8094\"\r\n",
      "#   # address = \"tcp6://127.0.0.1:8094\"\r\n",
      "#   # address = \"tcp6://[2001:db8::1]:8094\"\r\n",
      "#   # address = \"udp://127.0.0.1:8094\"\r\n",
      "#   # address = \"udp4://127.0.0.1:8094\"\r\n",
      "#   # address = \"udp6://127.0.0.1:8094\"\r\n",
      "#   # address = \"unix:///tmp/telegraf.sock\"\r\n",
      "#   # address = \"unixgram:///tmp/telegraf.sock\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Period between keep alive probes.\r\n",
      "#   ## Only applies to TCP sockets.\r\n",
      "#   ## 0 disables keep alive probes.\r\n",
      "#   ## Defaults to the OS configuration.\r\n",
      "#   # keep_alive_period = \"5m\"\r\n",
      "#\r\n",
      "#   ## Data format to generate.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   # data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Configuration for Wavefront server to send metrics to\r\n",
      "# [[outputs.wavefront]]\r\n",
      "#   ## DNS name of the wavefront proxy server\r\n",
      "#   host = \"wavefront.example.com\"\r\n",
      "#\r\n",
      "#   ## Port that the Wavefront proxy server listens on\r\n",
      "#   port = 2878\r\n",
      "#\r\n",
      "#   ## prefix for metrics keys\r\n",
      "#   #prefix = \"my.specific.prefix.\"\r\n",
      "#\r\n",
      "#   ## whether to use \"value\" for name of simple fields\r\n",
      "#   #simple_fields = false\r\n",
      "#\r\n",
      "#   ## character to use between metric and field name.  defaults to . (dot)\r\n",
      "#   #metric_separator = \".\"\r\n",
      "#\r\n",
      "#   ## Convert metric name paths to use metricSeperator character\r\n",
      "#   ## When true (default) will convert all _ (underscore) chartacters in final metric name\r\n",
      "#   #convert_paths = true\r\n",
      "#\r\n",
      "#   ## Use Regex to sanitize metric and tag names from invalid characters\r\n",
      "#   ## Regex is more thorough, but significantly slower\r\n",
      "#   #use_regex = false\r\n",
      "#\r\n",
      "#   ## point tags to use as the source name for Wavefront (if none found, host will be used)\r\n",
      "#   #source_override = [\"hostname\", \"agent_host\", \"node_host\"]\r\n",
      "#\r\n",
      "#   ## whether to convert boolean values to numeric values, with false -> 0.0 and true -> 1.0.  default true\r\n",
      "#   #convert_bool = true\r\n",
      "#\r\n",
      "#   ## Define a mapping, namespaced by metric prefix, from string values to numeric values\r\n",
      "#   ## The example below maps \"green\" -> 1.0, \"yellow\" -> 0.5, \"red\" -> 0.0 for\r\n",
      "#   ## any metrics beginning with \"elasticsearch\"\r\n",
      "#   #[[outputs.wavefront.string_to_number.elasticsearch]]\r\n",
      "#   #  green = 1.0\r\n",
      "#   #  yellow = 0.5\r\n",
      "#   #  red = 0.0\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "###############################################################################\r\n",
      "#                            PROCESSOR PLUGINS                                #\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "# # Convert values to another metric value type\r\n",
      "# [[processors.converter]]\r\n",
      "#   ## Tags to convert\r\n",
      "#   ##\r\n",
      "#   ## The table key determines the target type, and the array of key-values\r\n",
      "#   ## select the keys to convert.  The array may contain globs.\r\n",
      "#   ##   <target-type> = [<tag-key>...]\r\n",
      "#   [processors.converter.tags]\r\n",
      "#     string = []\r\n",
      "#     integer = []\r\n",
      "#     unsigned = []\r\n",
      "#     boolean = []\r\n",
      "#     float = []\r\n",
      "#\r\n",
      "#   ## Fields to convert\r\n",
      "#   ##\r\n",
      "#   ## The table key determines the target type, and the array of key-values\r\n",
      "#   ## select the keys to convert.  The array may contain globs.\r\n",
      "#   ##   <target-type> = [<field-key>...]\r\n",
      "#   [processors.converter.fields]\r\n",
      "#     tag = []\r\n",
      "#     string = []\r\n",
      "#     integer = []\r\n",
      "#     unsigned = []\r\n",
      "#     boolean = []\r\n",
      "#     float = []\r\n",
      "\r\n",
      "\r\n",
      "# # Apply metric modifications using override semantics.\r\n",
      "# [[processors.override]]\r\n",
      "#   ## All modifications on inputs and aggregators can be overridden:\r\n",
      "#   # name_override = \"new_name\"\r\n",
      "#   # name_prefix = \"new_name_prefix\"\r\n",
      "#   # name_suffix = \"new_name_suffix\"\r\n",
      "#\r\n",
      "#   ## Tags to be added (all values must be strings)\r\n",
      "#   # [processors.override.tags]\r\n",
      "#   #   additional_tag = \"tag_value\"\r\n",
      "\r\n",
      "\r\n",
      "# # Print all metrics that pass through this filter.\r\n",
      "# [[processors.printer]]\r\n",
      "\r\n",
      "\r\n",
      "# # Transforms tag and field values with regex pattern\r\n",
      "# [[processors.regex]]\r\n",
      "#   ## Tag and field conversions defined in a separate sub-tables\r\n",
      "#   # [[processors.regex.tags]]\r\n",
      "#   #   ## Tag to change\r\n",
      "#   #   key = \"resp_code\"\r\n",
      "#   #   ## Regular expression to match on a tag value\r\n",
      "#   #   pattern = \"^(\\\\d)\\\\d\\\\d$\"\r\n",
      "#   #   ## Pattern for constructing a new value (${1} represents first subgroup)\r\n",
      "#   #   replacement = \"${1}xx\"\r\n",
      "#\r\n",
      "#   # [[processors.regex.fields]]\r\n",
      "#   #   key = \"request\"\r\n",
      "#   #   ## All the power of the Go regular expressions available here\r\n",
      "#   #   ## For example, named subgroups\r\n",
      "#   #   pattern = \"^/api(?P<method>/[\\\\w/]+)\\\\S*\"\r\n",
      "#   #   replacement = \"${method}\"\r\n",
      "#   #   ## If result_key is present, a new field will be created\r\n",
      "#   #   ## instead of changing existing field\r\n",
      "#   #   result_key = \"method\"\r\n",
      "#\r\n",
      "#   ## Multiple conversions may be applied for one field sequentially\r\n",
      "#   ## Let's extract one more value\r\n",
      "#   # [[processors.regex.fields]]\r\n",
      "#   #   key = \"request\"\r\n",
      "#   #   pattern = \".*category=(\\\\w+).*\"\r\n",
      "#   #   replacement = \"${1}\"\r\n",
      "#   #   result_key = \"search_category\"\r\n",
      "\r\n",
      "\r\n",
      "# # Print all metrics that pass through this filter.\r\n",
      "# [[processors.topk]]\r\n",
      "#   ## How many seconds between aggregations\r\n",
      "#   # period = 10\r\n",
      "#\r\n",
      "#   ## How many top metrics to return\r\n",
      "#   # k = 10\r\n",
      "#\r\n",
      "#   ## Over which tags should the aggregation be done. Globs can be specified, in\r\n",
      "#   ## which case any tag matching the glob will aggregated over. If set to an\r\n",
      "#   ## empty list is no aggregation over tags is done\r\n",
      "#   # group_by = ['*']\r\n",
      "#\r\n",
      "#   ## Over which fields are the top k are calculated\r\n",
      "#   # fields = [\"value\"]\r\n",
      "#\r\n",
      "#   ## What aggregation to use. Options: sum, mean, min, max\r\n",
      "#   # aggregation = \"mean\"\r\n",
      "#\r\n",
      "#   ## Instead of the top k largest metrics, return the bottom k lowest metrics\r\n",
      "#   # bottomk = false\r\n",
      "#\r\n",
      "#   ## The plugin assigns each metric a GroupBy tag generated from its name and\r\n",
      "#   ## tags. If this setting is different than \"\" the plugin will add a\r\n",
      "#   ## tag (which name will be the value of this setting) to each metric with\r\n",
      "#   ## the value of the calculated GroupBy tag. Useful for debugging\r\n",
      "#   # add_groupby_tag = \"\"\r\n",
      "#\r\n",
      "#   ## These settings provide a way to know the position of each metric in\r\n",
      "#   ## the top k. The 'add_rank_field' setting allows to specify for which\r\n",
      "#   ## fields the position is required. If the list is non empty, then a field\r\n",
      "#   ## will be added to each and every metric for each string present in this\r\n",
      "#   ## setting. This field will contain the ranking of the group that\r\n",
      "#   ## the metric belonged to when aggregated over that field.\r\n",
      "#   ## The name of the field will be set to the name of the aggregation field,\r\n",
      "#   ## suffixed with the string '_topk_rank'\r\n",
      "#   # add_rank_fields = []\r\n",
      "#\r\n",
      "#   ## These settings provide a way to know what values the plugin is generating\r\n",
      "#   ## when aggregating metrics. The 'add_agregate_field' setting allows to\r\n",
      "#   ## specify for which fields the final aggregation value is required. If the\r\n",
      "#   ## list is non empty, then a field will be added to each every metric for\r\n",
      "#   ## each field present in this setting. This field will contain\r\n",
      "#   ## the computed aggregation for the group that the metric belonged to when\r\n",
      "#   ## aggregated over that field.\r\n",
      "#   ## The name of the field will be set to the name of the aggregation field,\r\n",
      "#   ## suffixed with the string '_topk_aggregate'\r\n",
      "#   # add_aggregate_fields = []\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "###############################################################################\r\n",
      "#                            AGGREGATOR PLUGINS                               #\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "# # Keep the aggregate basicstats of each metric passing through.\r\n",
      "# [[aggregators.basicstats]]\r\n",
      "#   ## General Aggregator Arguments:\r\n",
      "#   ## The period on which to flush & clear the aggregator.\r\n",
      "#   period = \"30s\"\r\n",
      "#   ## If true, the original metric will be dropped by the\r\n",
      "#   ## aggregator and will not get sent to the output plugins.\r\n",
      "#   drop_original = false\r\n",
      "\r\n",
      "\r\n",
      "# # Create aggregate histograms.\r\n",
      "# [[aggregators.histogram]]\r\n",
      "#   ## The period in which to flush the aggregator.\r\n",
      "#   period = \"30s\"\r\n",
      "#\r\n",
      "#   ## If true, the original metric will be dropped by the\r\n",
      "#   ## aggregator and will not get sent to the output plugins.\r\n",
      "#   drop_original = false\r\n",
      "#\r\n",
      "#   ## Example config that aggregates all fields of the metric.\r\n",
      "#   # [[aggregators.histogram.config]]\r\n",
      "#   #   ## The set of buckets.\r\n",
      "#   #   buckets = [0.0, 15.6, 34.5, 49.1, 71.5, 80.5, 94.5, 100.0]\r\n",
      "#   #   ## The name of metric.\r\n",
      "#   #   measurement_name = \"cpu\"\r\n",
      "#\r\n",
      "#   ## Example config that aggregates only specific fields of the metric.\r\n",
      "#   # [[aggregators.histogram.config]]\r\n",
      "#   #   ## The set of buckets.\r\n",
      "#   #   buckets = [0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\r\n",
      "#   #   ## The name of metric.\r\n",
      "#   #   measurement_name = \"diskio\"\r\n",
      "#   #   ## The concrete fields of metric\r\n",
      "#   #   fields = [\"io_time\", \"read_time\", \"write_time\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Keep the aggregate min/max of each metric passing through.\r\n",
      "# [[aggregators.minmax]]\r\n",
      "#   ## General Aggregator Arguments:\r\n",
      "#   ## The period on which to flush & clear the aggregator.\r\n",
      "#   period = \"30s\"\r\n",
      "#   ## If true, the original metric will be dropped by the\r\n",
      "#   ## aggregator and will not get sent to the output plugins.\r\n",
      "#   drop_original = false\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "###############################################################################\r\n",
      "#                            INPUT PLUGINS                                    #\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "# Read metrics about cpu usage\r\n",
      "[[inputs.cpu]]\r\n",
      "  ## Whether to report per-cpu stats or not\r\n",
      "  percpu = true\r\n",
      "  ## Whether to report total system cpu stats or not\r\n",
      "  totalcpu = true\r\n",
      "  ## If true, collect raw CPU time metrics.\r\n",
      "  collect_cpu_time = false\r\n",
      "  ## If true, compute and report the sum of all non-idle CPU states.\r\n",
      "  report_active = false\r\n",
      "\r\n",
      "\r\n",
      "# Read metrics about disk usage by mount point\r\n",
      "[[inputs.disk]]\r\n",
      "  ## By default stats will be gathered for all mount points.\r\n",
      "  ## Set mount_points will restrict the stats to only the specified mount points.\r\n",
      "  # mount_points = [\"/\"]\r\n",
      "\r\n",
      "  ## Ignore mount points by filesystem type.\r\n",
      "  ignore_fs = [\"tmpfs\", \"devtmpfs\", \"devfs\"]\r\n",
      "\r\n",
      "\r\n",
      "# Read metrics about disk IO by device\r\n",
      "[[inputs.diskio]]\r\n",
      "  ## By default, telegraf will gather stats for all devices including\r\n",
      "  ## disk partitions.\r\n",
      "  ## Setting devices will restrict the stats to the specified devices.\r\n",
      "  # devices = [\"sda\", \"sdb\", \"vd*\"]\r\n",
      "  ## Uncomment the following line if you need disk serial numbers.\r\n",
      "  # skip_serial_number = false\r\n",
      "  #\r\n",
      "  ## On systems which support it, device metadata can be added in the form of\r\n",
      "  ## tags.\r\n",
      "  ## Currently only Linux is supported via udev properties. You can view\r\n",
      "  ## available properties for a device by running:\r\n",
      "  ## 'udevadm info -q property -n /dev/sda'\r\n",
      "  # device_tags = [\"ID_FS_TYPE\", \"ID_FS_USAGE\"]\r\n",
      "  #\r\n",
      "  ## Using the same metadata source as device_tags, you can also customize the\r\n",
      "  ## name of the device via templates.\r\n",
      "  ## The 'name_templates' parameter is a list of templates to try and apply to\r\n",
      "  ## the device. The template may contain variables in the form of '$PROPERTY' or\r\n",
      "  ## '${PROPERTY}'. The first template which does not contain any variables not\r\n",
      "  ## present for the device is used as the device name tag.\r\n",
      "  ## The typical use case is for LVM volumes, to get the VG/LV name instead of\r\n",
      "  ## the near-meaningless DM-0 name.\r\n",
      "  # name_templates = [\"$ID_FS_LABEL\",\"$DM_VG_NAME/$DM_LV_NAME\"]\r\n",
      "\r\n",
      "\r\n",
      "# Get kernel statistics from /proc/stat\r\n",
      "[[inputs.kernel]]\r\n",
      "  # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# Read metrics about memory usage\r\n",
      "[[inputs.mem]]\r\n",
      "  # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# Get the number of processes and group them by status\r\n",
      "[[inputs.processes]]\r\n",
      "  # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# Read metrics about swap memory usage\r\n",
      "[[inputs.swap]]\r\n",
      "  # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# Read metrics about system load & uptime\r\n",
      "[[inputs.system]]\r\n",
      "  # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# # Read stats from aerospike server(s)\r\n",
      "# [[inputs.aerospike]]\r\n",
      "#   ## Aerospike servers to connect to (with port)\r\n",
      "#   ## This plugin will query all namespaces the aerospike\r\n",
      "#   ## server has configured and get stats for them.\r\n",
      "#   servers = [\"localhost:3000\"]\r\n",
      "#\r\n",
      "#   # username = \"telegraf\"\r\n",
      "#   # password = \"pa$$word\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # enable_tls = false\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## If false, skip chain & host verification\r\n",
      "#   # insecure_skip_verify = true\r\n",
      "\r\n",
      "\r\n",
      "# # Read Apache status information (mod_status)\r\n",
      "# [[inputs.apache]]\r\n",
      "#   ## An array of URLs to gather from, must be directed at the machine\r\n",
      "#   ## readable version of the mod_status page including the auto query string.\r\n",
      "#   ## Default is \"http://localhost/server-status?auto\".\r\n",
      "#   urls = [\"http://localhost/server-status?auto\"]\r\n",
      "#\r\n",
      "#   ## Credentials for basic HTTP authentication.\r\n",
      "#   # username = \"myuser\"\r\n",
      "#   # password = \"mypassword\"\r\n",
      "#\r\n",
      "#   ## Maximum time to receive response.\r\n",
      "#   # response_timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Gather metrics from Apache Aurora schedulers\r\n",
      "# [[inputs.aurora]]\r\n",
      "#   ## Schedulers are the base addresses of your Aurora Schedulers\r\n",
      "#   schedulers = [\"http://127.0.0.1:8081\"]\r\n",
      "#\r\n",
      "#   ## Set of role types to collect metrics from.\r\n",
      "#   ##\r\n",
      "#   ## The scheduler roles are checked each interval by contacting the\r\n",
      "#   ## scheduler nodes; zookeeper is not contacted.\r\n",
      "#   # roles = [\"leader\", \"follower\"]\r\n",
      "#\r\n",
      "#   ## Timeout is the max time for total network operations.\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Username and password are sent using HTTP Basic Auth.\r\n",
      "#   # username = \"username\"\r\n",
      "#   # password = \"pa$$word\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics of bcache from stats_total and dirty_data\r\n",
      "# [[inputs.bcache]]\r\n",
      "#   ## Bcache sets path\r\n",
      "#   ## If not specified, then default is:\r\n",
      "#   bcachePath = \"/sys/fs/bcache\"\r\n",
      "#\r\n",
      "#   ## By default, telegraf gather stats for all bcache devices\r\n",
      "#   ## Setting devices will restrict the stats to the specified\r\n",
      "#   ## bcache devices.\r\n",
      "#   bcacheDevs = [\"bcache0\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Collect bond interface status, slaves statuses and failures count\r\n",
      "# [[inputs.bond]]\r\n",
      "#   ## Sets 'proc' directory path\r\n",
      "#   ## If not specified, then default is /proc\r\n",
      "#   # host_proc = \"/proc\"\r\n",
      "#\r\n",
      "#   ## By default, telegraf gather stats for all bond interfaces\r\n",
      "#   ## Setting interfaces will restrict the stats to the specified\r\n",
      "#   ## bond interfaces.\r\n",
      "#   # bond_interfaces = [\"bond0\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Collect Kafka topics and consumers status from Burrow HTTP API.\r\n",
      "# [[inputs.burrow]]\r\n",
      "#   ## Burrow API endpoints in format \"schema://host:port\".\r\n",
      "#   ## Default is \"http://localhost:8000\".\r\n",
      "#   servers = [\"http://localhost:8000\"]\r\n",
      "#\r\n",
      "#   ## Override Burrow API prefix.\r\n",
      "#   ## Useful when Burrow is behind reverse-proxy.\r\n",
      "#   # api_prefix = \"/v3/kafka\"\r\n",
      "#\r\n",
      "#   ## Maximum time to receive response.\r\n",
      "#   # response_timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Limit per-server concurrent connections.\r\n",
      "#   ## Useful in case of large number of topics or consumer groups.\r\n",
      "#   # concurrent_connections = 20\r\n",
      "#\r\n",
      "#   ## Filter clusters, default is no filtering.\r\n",
      "#   ## Values can be specified as glob patterns.\r\n",
      "#   # clusters_include = []\r\n",
      "#   # clusters_exclude = []\r\n",
      "#\r\n",
      "#   ## Filter consumer groups, default is no filtering.\r\n",
      "#   ## Values can be specified as glob patterns.\r\n",
      "#   # groups_include = []\r\n",
      "#   # groups_exclude = []\r\n",
      "#\r\n",
      "#   ## Filter topics, default is no filtering.\r\n",
      "#   ## Values can be specified as glob patterns.\r\n",
      "#   # topics_include = []\r\n",
      "#   # topics_exclude = []\r\n",
      "#\r\n",
      "#   ## Credentials for basic HTTP authentication.\r\n",
      "#   # username = \"\"\r\n",
      "#   # password = \"\"\r\n",
      "#\r\n",
      "#   ## Optional SSL config\r\n",
      "#   # ssl_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # ssl_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # ssl_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Collects performance metrics from the MON and OSD nodes in a Ceph storage cluster.\r\n",
      "# [[inputs.ceph]]\r\n",
      "#   ## This is the recommended interval to poll.  Too frequent and you will lose\r\n",
      "#   ## data points due to timeouts during rebalancing and recovery\r\n",
      "#   interval = '1m'\r\n",
      "#\r\n",
      "#   ## All configuration values are optional, defaults are shown below\r\n",
      "#\r\n",
      "#   ## location of ceph binary\r\n",
      "#   ceph_binary = \"/usr/bin/ceph\"\r\n",
      "#\r\n",
      "#   ## directory in which to look for socket files\r\n",
      "#   socket_dir = \"/var/run/ceph\"\r\n",
      "#\r\n",
      "#   ## prefix of MON and OSD socket files, used to determine socket type\r\n",
      "#   mon_prefix = \"ceph-mon\"\r\n",
      "#   osd_prefix = \"ceph-osd\"\r\n",
      "#\r\n",
      "#   ## suffix used to identify socket files\r\n",
      "#   socket_suffix = \"asok\"\r\n",
      "#\r\n",
      "#   ## Ceph user to authenticate as\r\n",
      "#   ceph_user = \"client.admin\"\r\n",
      "#\r\n",
      "#   ## Ceph configuration to use to locate the cluster\r\n",
      "#   ceph_config = \"/etc/ceph/ceph.conf\"\r\n",
      "#\r\n",
      "#   ## Whether to gather statistics via the admin socket\r\n",
      "#   gather_admin_socket_stats = true\r\n",
      "#\r\n",
      "#   ## Whether to gather statistics via ceph commands\r\n",
      "#   gather_cluster_stats = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read specific statistics per cgroup\r\n",
      "# [[inputs.cgroup]]\r\n",
      "#   ## Directories in which to look for files, globs are supported.\r\n",
      "#   ## Consider restricting paths to the set of cgroups you really\r\n",
      "#   ## want to monitor if you have a large number of cgroups, to avoid\r\n",
      "#   ## any cardinality issues.\r\n",
      "#   # paths = [\r\n",
      "#   #   \"/cgroup/memory\",\r\n",
      "#   #   \"/cgroup/memory/child1\",\r\n",
      "#   #   \"/cgroup/memory/child2/*\",\r\n",
      "#   # ]\r\n",
      "#   ## cgroup stat fields, as file names, globs are supported.\r\n",
      "#   ## these file names are appended to each path from above.\r\n",
      "#   # files = [\"memory.*usage*\", \"memory.limit_in_bytes\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Get standard chrony metrics, requires chronyc executable.\r\n",
      "# [[inputs.chrony]]\r\n",
      "#   ## If true, chronyc tries to perform a DNS lookup for the time server.\r\n",
      "#   # dns_lookup = false\r\n",
      "\r\n",
      "\r\n",
      "# # Pull Metric Statistics from Amazon CloudWatch\r\n",
      "# [[inputs.cloudwatch]]\r\n",
      "#   ## Amazon Region\r\n",
      "#   region = \"us-east-1\"\r\n",
      "#\r\n",
      "#   ## Amazon Credentials\r\n",
      "#   ## Credentials are loaded in the following order\r\n",
      "#   ## 1) Assumed credentials via STS if role_arn is specified\r\n",
      "#   ## 2) explicit credentials from 'access_key' and 'secret_key'\r\n",
      "#   ## 3) shared profile from 'profile'\r\n",
      "#   ## 4) environment variables\r\n",
      "#   ## 5) shared credentials file\r\n",
      "#   ## 6) EC2 Instance Profile\r\n",
      "#   #access_key = \"\"\r\n",
      "#   #secret_key = \"\"\r\n",
      "#   #token = \"\"\r\n",
      "#   #role_arn = \"\"\r\n",
      "#   #profile = \"\"\r\n",
      "#   #shared_credential_file = \"\"\r\n",
      "#\r\n",
      "#   # The minimum period for Cloudwatch metrics is 1 minute (60s). However not all\r\n",
      "#   # metrics are made available to the 1 minute period. Some are collected at\r\n",
      "#   # 3 minute, 5 minute, or larger intervals. See https://aws.amazon.com/cloudwatch/faqs/#monitoring.\r\n",
      "#   # Note that if a period is configured that is smaller than the minimum for a\r\n",
      "#   # particular metric, that metric will not be returned by the Cloudwatch API\r\n",
      "#   # and will not be collected by Telegraf.\r\n",
      "#   #\r\n",
      "#   ## Requested CloudWatch aggregation Period (required - must be a multiple of 60s)\r\n",
      "#   period = \"5m\"\r\n",
      "#\r\n",
      "#   ## Collection Delay (required - must account for metrics availability via CloudWatch API)\r\n",
      "#   delay = \"5m\"\r\n",
      "#\r\n",
      "#   ## Recommended: use metric 'interval' that is a multiple of 'period' to avoid\r\n",
      "#   ## gaps or overlap in pulled data\r\n",
      "#   interval = \"5m\"\r\n",
      "#\r\n",
      "#   ## Configure the TTL for the internal cache of metrics.\r\n",
      "#   ## Defaults to 1 hr if not specified\r\n",
      "#   #cache_ttl = \"10m\"\r\n",
      "#\r\n",
      "#   ## Metric Statistic Namespace (required)\r\n",
      "#   namespace = \"AWS/ELB\"\r\n",
      "#\r\n",
      "#   ## Maximum requests per second. Note that the global default AWS rate limit is\r\n",
      "#   ## 400 reqs/sec, so if you define multiple namespaces, these should add up to a\r\n",
      "#   ## maximum of 400. Optional - default value is 200.\r\n",
      "#   ## See http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_limits.html\r\n",
      "#   ratelimit = 200\r\n",
      "#\r\n",
      "#   ## Metrics to Pull (optional)\r\n",
      "#   ## Defaults to all Metrics in Namespace if nothing is provided\r\n",
      "#   ## Refreshes Namespace available metrics every 1h\r\n",
      "#   #[[inputs.cloudwatch.metrics]]\r\n",
      "#   #  names = [\"Latency\", \"RequestCount\"]\r\n",
      "#   #\r\n",
      "#   #  ## Dimension filters for Metric (optional)\r\n",
      "#   #  [[inputs.cloudwatch.metrics.dimensions]]\r\n",
      "#   #    name = \"LoadBalancerName\"\r\n",
      "#   #    value = \"p-example\"\r\n",
      "\r\n",
      "\r\n",
      "# # Collects conntrack stats from the configured directories and files.\r\n",
      "# [[inputs.conntrack]]\r\n",
      "#    ## The following defaults would work with multiple versions of conntrack.\r\n",
      "#    ## Note the nf_ and ip_ filename prefixes are mutually exclusive across\r\n",
      "#    ## kernel versions, as are the directory locations.\r\n",
      "#\r\n",
      "#    ## Superset of filenames to look for within the conntrack dirs.\r\n",
      "#    ## Missing files will be ignored.\r\n",
      "#    files = [\"ip_conntrack_count\",\"ip_conntrack_max\",\r\n",
      "#             \"nf_conntrack_count\",\"nf_conntrack_max\"]\r\n",
      "#\r\n",
      "#    ## Directories to search within for the conntrack files above.\r\n",
      "#    ## Missing directrories will be ignored.\r\n",
      "#    dirs = [\"/proc/sys/net/ipv4/netfilter\",\"/proc/sys/net/netfilter\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Gather health check statuses from services registered in Consul\r\n",
      "# [[inputs.consul]]\r\n",
      "#   ## Consul server address\r\n",
      "#   # address = \"localhost\"\r\n",
      "#\r\n",
      "#   ## URI scheme for the Consul server, one of \"http\", \"https\"\r\n",
      "#   # scheme = \"http\"\r\n",
      "#\r\n",
      "#   ## ACL token used in every request\r\n",
      "#   # token = \"\"\r\n",
      "#\r\n",
      "#   ## HTTP Basic Authentication username and password.\r\n",
      "#   # username = \"\"\r\n",
      "#   # password = \"\"\r\n",
      "#\r\n",
      "#   ## Data centre to query the health checks from\r\n",
      "#   # datacentre = \"\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = true\r\n",
      "#\r\n",
      "#   ## Consul checks' tag splitting\r\n",
      "#   # When tags are formatted like \"key:value\" with \":\" as a delimiter then\r\n",
      "#   # they will be splitted and reported as proper key:value in Telegraf\r\n",
      "#   # tag_delimiter = \":\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many couchbase clusters\r\n",
      "# [[inputs.couchbase]]\r\n",
      "#   ## specify servers via a url matching:\r\n",
      "#   ##  [protocol://][:password]@address[:port]\r\n",
      "#   ##  e.g.\r\n",
      "#   ##    http://couchbase-0.example.com/\r\n",
      "#   ##    http://admin:secret@couchbase-0.example.com:8091/\r\n",
      "#   ##\r\n",
      "#   ## If no servers are specified, then localhost is used as the host.\r\n",
      "#   ## If no protocol is specified, HTTP is used.\r\n",
      "#   ## If no port is specified, 8091 is used.\r\n",
      "#   servers = [\"http://localhost:8091\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read CouchDB Stats from one or more servers\r\n",
      "# [[inputs.couchdb]]\r\n",
      "#   ## Works with CouchDB stats endpoints out of the box\r\n",
      "#   ## Multiple HOSTs from which to read CouchDB stats:\r\n",
      "#   hosts = [\"http://localhost:8086/_stats\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Input plugin for DC/OS metrics\r\n",
      "# [[inputs.dcos]]\r\n",
      "#   ## The DC/OS cluster URL.\r\n",
      "#   cluster_url = \"https://dcos-ee-master-1\"\r\n",
      "#\r\n",
      "#   ## The ID of the service account.\r\n",
      "#   service_account_id = \"telegraf\"\r\n",
      "#   ## The private key file for the service account.\r\n",
      "#   service_account_private_key = \"/etc/telegraf/telegraf-sa-key.pem\"\r\n",
      "#\r\n",
      "#   ## Path containing login token.  If set, will read on every gather.\r\n",
      "#   # token_file = \"/home/dcos/.dcos/token\"\r\n",
      "#\r\n",
      "#   ## In all filter options if both include and exclude are empty all items\r\n",
      "#   ## will be collected.  Arrays may contain glob patterns.\r\n",
      "#   ##\r\n",
      "#   ## Node IDs to collect metrics from.  If a node is excluded, no metrics will\r\n",
      "#   ## be collected for its containers or apps.\r\n",
      "#   # node_include = []\r\n",
      "#   # node_exclude = []\r\n",
      "#   ## Container IDs to collect container metrics from.\r\n",
      "#   # container_include = []\r\n",
      "#   # container_exclude = []\r\n",
      "#   ## Container IDs to collect app metrics from.\r\n",
      "#   # app_include = []\r\n",
      "#   # app_exclude = []\r\n",
      "#\r\n",
      "#   ## Maximum concurrent connections to the cluster.\r\n",
      "#   # max_connections = 10\r\n",
      "#   ## Maximum time to receive a response from cluster.\r\n",
      "#   # response_timeout = \"20s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## If false, skip chain & host verification\r\n",
      "#   # insecure_skip_verify = true\r\n",
      "#\r\n",
      "#   ## Recommended filtering to reduce series cardinality.\r\n",
      "#   # [inputs.dcos.tagdrop]\r\n",
      "#   #   path = [\"/var/lib/mesos/slave/slaves/*\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many disque servers\r\n",
      "# [[inputs.disque]]\r\n",
      "#   ## An array of URI to gather stats about. Specify an ip or hostname\r\n",
      "#   ## with optional port and password.\r\n",
      "#   ## ie disque://localhost, disque://10.10.3.33:18832, 10.0.0.1:10000, etc.\r\n",
      "#   ## If no servers are specified, then localhost is used as the host.\r\n",
      "#   servers = [\"localhost\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Provide a native collection for dmsetup based statistics for dm-cache\r\n",
      "# [[inputs.dmcache]]\r\n",
      "#   ## Whether to report per-device stats or not\r\n",
      "#   per_device = true\r\n",
      "\r\n",
      "\r\n",
      "# # Query given DNS server and gives statistics\r\n",
      "# [[inputs.dns_query]]\r\n",
      "#   ## servers to query\r\n",
      "#   servers = [\"8.8.8.8\"]\r\n",
      "#\r\n",
      "#   ## Network is the network protocol name.\r\n",
      "#   # network = \"udp\"\r\n",
      "#\r\n",
      "#   ## Domains or subdomains to query.\r\n",
      "#   # domains = [\".\"]\r\n",
      "#\r\n",
      "#   ## Query record type.\r\n",
      "#   ## Posible values: A, AAAA, CNAME, MX, NS, PTR, TXT, SOA, SPF, SRV.\r\n",
      "#   # record_type = \"A\"\r\n",
      "#\r\n",
      "#   ## Dns server port.\r\n",
      "#   # port = 53\r\n",
      "#\r\n",
      "#   ## Query timeout in seconds.\r\n",
      "#   # timeout = 2\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics about docker containers\r\n",
      "# [[inputs.docker]]\r\n",
      "#   ## Docker Endpoint\r\n",
      "#   ##   To use TCP, set endpoint = \"tcp://[ip]:[port]\"\r\n",
      "#   ##   To use environment variables (ie, docker-machine), set endpoint = \"ENV\"\r\n",
      "#   endpoint = \"unix:///var/run/docker.sock\"\r\n",
      "#\r\n",
      "#   ## Set to true to collect Swarm metrics(desired_replicas, running_replicas)\r\n",
      "#   gather_services = false\r\n",
      "#\r\n",
      "#   ## Only collect metrics for these containers, collect all if empty\r\n",
      "#   container_names = []\r\n",
      "#\r\n",
      "#   ## Containers to include and exclude. Globs accepted.\r\n",
      "#   ## Note that an empty array for both will include all containers\r\n",
      "#   container_name_include = []\r\n",
      "#   container_name_exclude = []\r\n",
      "#\r\n",
      "#   ## Container states to include and exclude. Globs accepted.\r\n",
      "#   ## When empty only containers in the \"running\" state will be captured.\r\n",
      "#   # container_state_include = []\r\n",
      "#   # container_state_exclude = []\r\n",
      "#\r\n",
      "#   ## Timeout for docker list, info, and stats commands\r\n",
      "#   timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Whether to report for each container per-device blkio (8:0, 8:1...) and\r\n",
      "#   ## network (eth0, eth1, ...) stats or not\r\n",
      "#   perdevice = true\r\n",
      "#   ## Whether to report for each container total blkio and network stats or not\r\n",
      "#   total = false\r\n",
      "#   ## Which environment variables should we use as a tag\r\n",
      "#   ##tag_env = [\"JAVA_HOME\", \"HEAP_SIZE\"]\r\n",
      "#\r\n",
      "#   ## docker labels to include and exclude as tags.  Globs accepted.\r\n",
      "#   ## Note that an empty array for both will include all labels as tags\r\n",
      "#   docker_label_include = []\r\n",
      "#   docker_label_exclude = []\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read statistics from one or many dovecot servers\r\n",
      "# [[inputs.dovecot]]\r\n",
      "#   ## specify dovecot servers via an address:port list\r\n",
      "#   ##  e.g.\r\n",
      "#   ##    localhost:24242\r\n",
      "#   ##\r\n",
      "#   ## If no servers are specified, then localhost is used as the host.\r\n",
      "#   servers = [\"localhost:24242\"]\r\n",
      "#   ## Type is one of \"user\", \"domain\", \"ip\", or \"global\"\r\n",
      "#   type = \"global\"\r\n",
      "#   ## Wildcard matches like \"*.com\". An empty string \"\" is same as \"*\"\r\n",
      "#   ## If type = \"ip\" filters should be <IP/network>\r\n",
      "#   filters = [\"\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read stats from one or more Elasticsearch servers or clusters\r\n",
      "# [[inputs.elasticsearch]]\r\n",
      "#   ## specify a list of one or more Elasticsearch servers\r\n",
      "#   # you can add username and password to your url to use basic authentication:\r\n",
      "#   # servers = [\"http://user:pass@localhost:9200\"]\r\n",
      "#   servers = [\"http://localhost:9200\"]\r\n",
      "#\r\n",
      "#   ## Timeout for HTTP requests to the elastic search server(s)\r\n",
      "#   http_timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## When local is true (the default), the node will read only its own stats.\r\n",
      "#   ## Set local to false when you want to read the node stats from all nodes\r\n",
      "#   ## of the cluster.\r\n",
      "#   local = true\r\n",
      "#\r\n",
      "#   ## Set cluster_health to true when you want to also obtain cluster health stats\r\n",
      "#   cluster_health = false\r\n",
      "#\r\n",
      "#   ## Adjust cluster_health_level when you want to also obtain detailed health stats\r\n",
      "#   ## The options are\r\n",
      "#   ##  - indices (default)\r\n",
      "#   ##  - cluster\r\n",
      "#   # cluster_health_level = \"indices\"\r\n",
      "#\r\n",
      "#   ## Set cluster_stats to true when you want to also obtain cluster stats from the\r\n",
      "#   ## Master node.\r\n",
      "#   cluster_stats = false\r\n",
      "#\r\n",
      "#   ## node_stats is a list of sub-stats that you want to have gathered. Valid options\r\n",
      "#   ## are \"indices\", \"os\", \"process\", \"jvm\", \"thread_pool\", \"fs\", \"transport\", \"http\",\r\n",
      "#   ## \"breaker\". Per default, all stats are gathered.\r\n",
      "#   # node_stats = [\"jvm\", \"http\"]\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or more commands that can output to stdout\r\n",
      "# [[inputs.exec]]\r\n",
      "#   ## Commands array\r\n",
      "#   commands = [\r\n",
      "#     \"/tmp/test.sh\",\r\n",
      "#     \"/usr/bin/mycollector --foo=bar\",\r\n",
      "#     \"/tmp/collect_*.sh\"\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   ## Timeout for each command to complete.\r\n",
      "#   timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## measurement name suffix (for separating different commands)\r\n",
      "#   name_suffix = \"_mycollector\"\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from fail2ban.\r\n",
      "# [[inputs.fail2ban]]\r\n",
      "#   ## Use sudo to run fail2ban-client\r\n",
      "#   use_sudo = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read devices value(s) from a Fibaro controller\r\n",
      "# [[inputs.fibaro]]\r\n",
      "#   ## Required Fibaro controller address/hostname.\r\n",
      "#   ## Note: at the time of writing this plugin, Fibaro only implemented http - no https available\r\n",
      "#   url = \"http://<controller>:80\"\r\n",
      "#\r\n",
      "#   ## Required credentials to access the API (http://<controller/api/<component>)\r\n",
      "#   username = \"<username>\"\r\n",
      "#   password = \"<password>\"\r\n",
      "#\r\n",
      "#   ## Amount of time allowed to complete the HTTP request\r\n",
      "#   # timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read stats about given file(s)\r\n",
      "# [[inputs.filestat]]\r\n",
      "#   ## Files to gather stats about.\r\n",
      "#   ## These accept standard unix glob matching rules, but with the addition of\r\n",
      "#   ## ** as a \"super asterisk\". ie:\r\n",
      "#   ##   \"/var/log/**.log\"  -> recursively find all .log files in /var/log\r\n",
      "#   ##   \"/var/log/*/*.log\" -> find all .log files with a parent dir in /var/log\r\n",
      "#   ##   \"/var/log/apache.log\" -> just tail the apache log file\r\n",
      "#   ##\r\n",
      "#   ## See https://github.com/gobwas/glob for more examples\r\n",
      "#   ##\r\n",
      "#   files = [\"/var/log/**.log\"]\r\n",
      "#   ## If true, read the entire file and calculate an md5 checksum.\r\n",
      "#   md5 = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics exposed by fluentd in_monitor plugin\r\n",
      "# [[inputs.fluentd]]\r\n",
      "#   ## This plugin reads information exposed by fluentd (using /api/plugins.json endpoint).\r\n",
      "#   ##\r\n",
      "#   ## Endpoint:\r\n",
      "#   ## - only one URI is allowed\r\n",
      "#   ## - https is not supported\r\n",
      "#   endpoint = \"http://localhost:24220/api/plugins.json\"\r\n",
      "#\r\n",
      "#   ## Define which plugins have to be excluded (based on \"type\" field - e.g. monitor_agent)\r\n",
      "#   exclude = [\r\n",
      "# \t  \"monitor_agent\",\r\n",
      "# \t  \"dummy\",\r\n",
      "#   ]\r\n",
      "\r\n",
      "\r\n",
      "# # Read flattened metrics from one or more GrayLog HTTP endpoints\r\n",
      "# [[inputs.graylog]]\r\n",
      "#   ## API endpoint, currently supported API:\r\n",
      "#   ##\r\n",
      "#   ##   - multiple  (Ex http://<host>:12900/system/metrics/multiple)\r\n",
      "#   ##   - namespace (Ex http://<host>:12900/system/metrics/namespace/{namespace})\r\n",
      "#   ##\r\n",
      "#   ## For namespace endpoint, the metrics array will be ignored for that call.\r\n",
      "#   ## Endpoint can contain namespace and multiple type calls.\r\n",
      "#   ##\r\n",
      "#   ## Please check http://[graylog-server-ip]:12900/api-browser for full list\r\n",
      "#   ## of endpoints\r\n",
      "#   servers = [\r\n",
      "#     \"http://[graylog-server-ip]:12900/system/metrics/multiple\",\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   ## Metrics list\r\n",
      "#   ## List of metrics can be found on Graylog webservice documentation.\r\n",
      "#   ## Or by hitting the the web service api at:\r\n",
      "#   ##   http://[graylog-host]:12900/system/metrics\r\n",
      "#   metrics = [\r\n",
      "#     \"jvm.cl.loaded\",\r\n",
      "#     \"jvm.memory.pools.Metaspace.committed\"\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   ## Username and password\r\n",
      "#   username = \"\"\r\n",
      "#   password = \"\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics of haproxy, via socket or csv stats page\r\n",
      "# [[inputs.haproxy]]\r\n",
      "#   ## An array of address to gather stats about. Specify an ip on hostname\r\n",
      "#   ## with optional port. ie localhost, 10.10.3.33:1936, etc.\r\n",
      "#   ## Make sure you specify the complete path to the stats endpoint\r\n",
      "#   ## including the protocol, ie http://10.10.3.33:1936/haproxy?stats\r\n",
      "#\r\n",
      "#   ## If no servers are specified, then default to 127.0.0.1:1936/haproxy?stats\r\n",
      "#   servers = [\"http://myhaproxy.com:1936/haproxy?stats\"]\r\n",
      "#\r\n",
      "#   ## You can also use local socket with standard wildcard globbing.\r\n",
      "#   ## Server address not starting with 'http' will be treated as a possible\r\n",
      "#   ## socket, so both examples below are valid.\r\n",
      "#   # servers = [\"socket:/run/haproxy/admin.sock\", \"/run/haproxy/*.sock\"]\r\n",
      "#\r\n",
      "#   ## By default, some of the fields are renamed from what haproxy calls them.\r\n",
      "#   ## Setting this option to true results in the plugin keeping the original\r\n",
      "#   ## field names.\r\n",
      "#   # keep_field_names = false\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Monitor disks' temperatures using hddtemp\r\n",
      "# [[inputs.hddtemp]]\r\n",
      "#   ## By default, telegraf gathers temps data from all disks detected by the\r\n",
      "#   ## hddtemp.\r\n",
      "#   ##\r\n",
      "#   ## Only collect temps from the selected disks.\r\n",
      "#   ##\r\n",
      "#   ## A * as the device name will return the temperature values of all disks.\r\n",
      "#   ##\r\n",
      "#   # address = \"127.0.0.1:7634\"\r\n",
      "#   # devices = [\"sda\", \"*\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read formatted metrics from one or more HTTP endpoints\r\n",
      "# [[inputs.http]]\r\n",
      "#   ## One or more URLs from which to read formatted metrics\r\n",
      "#   urls = [\r\n",
      "#     \"http://localhost/metrics\"\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   ## HTTP method\r\n",
      "#   # method = \"GET\"\r\n",
      "#\r\n",
      "#   ## Optional HTTP headers\r\n",
      "#   # headers = {\"X-Special-Header\" = \"Special-Value\"}\r\n",
      "#\r\n",
      "#   ## Optional HTTP Basic Auth Credentials\r\n",
      "#   # username = \"username\"\r\n",
      "#   # password = \"pa$$word\"\r\n",
      "#\r\n",
      "#   ## Tag all metrics with the url\r\n",
      "#   # tag_url = true\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Amount of time allowed to complete the HTTP request\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   # data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # HTTP/HTTPS request given an address a method and a timeout\r\n",
      "# [[inputs.http_response]]\r\n",
      "#   ## Server address (default http://localhost)\r\n",
      "#   # address = \"http://localhost\"\r\n",
      "#\r\n",
      "#   ## Set http_proxy (telegraf uses the system wide proxy settings if it's is not set)\r\n",
      "#   # http_proxy = \"http://localhost:8888\"\r\n",
      "#\r\n",
      "#   ## Set response_timeout (default 5 seconds)\r\n",
      "#   # response_timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## HTTP Request Method\r\n",
      "#   # method = \"GET\"\r\n",
      "#\r\n",
      "#   ## Whether to follow redirects from the server (defaults to false)\r\n",
      "#   # follow_redirects = false\r\n",
      "#\r\n",
      "#   ## Optional HTTP Request Body\r\n",
      "#   # body = '''\r\n",
      "#   # {'fake':'data'}\r\n",
      "#   # '''\r\n",
      "#\r\n",
      "#   ## Optional substring or regex match in body of the response\r\n",
      "#   # response_string_match = \"\\\"service_status\\\": \\\"up\\\"\"\r\n",
      "#   # response_string_match = \"ok\"\r\n",
      "#   # response_string_match = \"\\\".*_status\\\".?:.?\\\"up\\\"\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## HTTP Request Headers (all values must be strings)\r\n",
      "#   # [inputs.http_response.headers]\r\n",
      "#   #   Host = \"github.com\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read flattened metrics from one or more JSON HTTP endpoints\r\n",
      "# [[inputs.httpjson]]\r\n",
      "#   ## NOTE This plugin only reads numerical measurements, strings and booleans\r\n",
      "#   ## will be ignored.\r\n",
      "#\r\n",
      "#   ## Name for the service being polled.  Will be appended to the name of the\r\n",
      "#   ## measurement e.g. httpjson_webserver_stats\r\n",
      "#   ##\r\n",
      "#   ## Deprecated (1.3.0): Use name_override, name_suffix, name_prefix instead.\r\n",
      "#   name = \"webserver_stats\"\r\n",
      "#\r\n",
      "#   ## URL of each server in the service's cluster\r\n",
      "#   servers = [\r\n",
      "#     \"http://localhost:9999/stats/\",\r\n",
      "#     \"http://localhost:9998/stats/\",\r\n",
      "#   ]\r\n",
      "#   ## Set response_timeout (default 5 seconds)\r\n",
      "#   response_timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## HTTP method to use: GET or POST (case-sensitive)\r\n",
      "#   method = \"GET\"\r\n",
      "#\r\n",
      "#   ## List of tag names to extract from top-level of JSON server response\r\n",
      "#   # tag_keys = [\r\n",
      "#   #   \"my_tag_1\",\r\n",
      "#   #   \"my_tag_2\"\r\n",
      "#   # ]\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## HTTP parameters (all values must be strings).  For \"GET\" requests, data\r\n",
      "#   ## will be included in the query.  For \"POST\" requests, data will be included\r\n",
      "#   ## in the request body as \"x-www-form-urlencoded\".\r\n",
      "#   # [inputs.httpjson.parameters]\r\n",
      "#   #   event_type = \"cpu_spike\"\r\n",
      "#   #   threshold = \"0.75\"\r\n",
      "#\r\n",
      "#   ## HTTP Headers (all values must be strings)\r\n",
      "#   # [inputs.httpjson.headers]\r\n",
      "#   #   X-Auth-Token = \"my-xauth-token\"\r\n",
      "#   #   apiVersion = \"v1\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read InfluxDB-formatted JSON metrics from one or more HTTP endpoints\r\n",
      "# [[inputs.influxdb]]\r\n",
      "#   ## Works with InfluxDB debug endpoints out of the box,\r\n",
      "#   ## but other services can use this format too.\r\n",
      "#   ## See the influxdb plugin's README for more details.\r\n",
      "#\r\n",
      "#   ## Multiple URLs from which to read InfluxDB-formatted JSON\r\n",
      "#   ## Default is \"http://localhost:8086/debug/vars\".\r\n",
      "#   urls = [\r\n",
      "#     \"http://localhost:8086/debug/vars\"\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## http request & header timeout\r\n",
      "#   timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Collect statistics about itself\r\n",
      "# [[inputs.internal]]\r\n",
      "#   ## If true, collect telegraf memory stats.\r\n",
      "#   # collect_memstats = true\r\n",
      "\r\n",
      "\r\n",
      "# # This plugin gathers interrupts data from /proc/interrupts and /proc/softirqs.\r\n",
      "# [[inputs.interrupts]]\r\n",
      "#   ## To filter which IRQs to collect, make use of tagpass / tagdrop, i.e.\r\n",
      "#   # [inputs.interrupts.tagdrop]\r\n",
      "#     # irq = [ \"NET_RX\", \"TASKLET\" ]\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from the bare metal servers via IPMI\r\n",
      "# [[inputs.ipmi_sensor]]\r\n",
      "#   ## optionally specify the path to the ipmitool executable\r\n",
      "#   # path = \"/usr/bin/ipmitool\"\r\n",
      "#   ##\r\n",
      "#   ## optionally force session privilege level. Can be CALLBACK, USER, OPERATOR, ADMINISTRATOR\r\n",
      "#   # privilege = \"ADMINISTRATOR\"\r\n",
      "#   ##\r\n",
      "#   ## optionally specify one or more servers via a url matching\r\n",
      "#   ##  [username[:password]@][protocol[(address)]]\r\n",
      "#   ##  e.g.\r\n",
      "#   ##    root:passwd@lan(127.0.0.1)\r\n",
      "#   ##\r\n",
      "#   ## if no servers are specified, local machine sensor stats will be queried\r\n",
      "#   ##\r\n",
      "#   # servers = [\"USERID:PASSW0RD@lan(192.168.1.1)\"]\r\n",
      "#\r\n",
      "#   ## Recommended: use metric 'interval' that is a multiple of 'timeout' to avoid\r\n",
      "#   ## gaps or overlap in pulled data\r\n",
      "#   interval = \"30s\"\r\n",
      "#\r\n",
      "#   ## Timeout for the ipmitool command to complete\r\n",
      "#   timeout = \"20s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Gather packets and bytes counters from Linux ipsets\r\n",
      "# [[inputs.ipset]]\r\n",
      "#   ## By default, we only show sets which have already matched at least 1 packet.\r\n",
      "#   ## set include_unmatched_sets = true to gather them all.\r\n",
      "#   include_unmatched_sets = false\r\n",
      "#   ## Adjust your sudo settings appropriately if using this option (\"sudo ipset save\")\r\n",
      "#   use_sudo = false\r\n",
      "#   ## The default timeout of 1s for ipset execution can be overridden here:\r\n",
      "#   # timeout = \"1s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Gather packets and bytes throughput from iptables\r\n",
      "# [[inputs.iptables]]\r\n",
      "#   ## iptables require root access on most systems.\r\n",
      "#   ## Setting 'use_sudo' to true will make use of sudo to run iptables.\r\n",
      "#   ## Users must configure sudo to allow telegraf user to run iptables with no password.\r\n",
      "#   ## iptables can be restricted to only list command \"iptables -nvL\".\r\n",
      "#   use_sudo = false\r\n",
      "#   ## Setting 'use_lock' to true runs iptables with the \"-w\" option.\r\n",
      "#   ## Adjust your sudo settings appropriately if using this option (\"iptables -wnvl\")\r\n",
      "#   use_lock = false\r\n",
      "#   ## defines the table to monitor:\r\n",
      "#   table = \"filter\"\r\n",
      "#   ## defines the chains to monitor.\r\n",
      "#   ## NOTE: iptables rules without a comment will not be monitored.\r\n",
      "#   ## Read the plugin documentation for more information.\r\n",
      "#   chains = [ \"INPUT\" ]\r\n",
      "\r\n",
      "\r\n",
      "# # Read JMX metrics through Jolokia\r\n",
      "# [[inputs.jolokia]]\r\n",
      "#   # DEPRECATED: the jolokia plugin has been deprecated in favor of the\r\n",
      "#   # jolokia2 plugin\r\n",
      "#   # see https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2\r\n",
      "#\r\n",
      "#   ## This is the context root used to compose the jolokia url\r\n",
      "#   ## NOTE that Jolokia requires a trailing slash at the end of the context root\r\n",
      "#   ## NOTE that your jolokia security policy must allow for POST requests.\r\n",
      "#   context = \"/jolokia/\"\r\n",
      "#\r\n",
      "#   ## This specifies the mode used\r\n",
      "#   # mode = \"proxy\"\r\n",
      "#   #\r\n",
      "#   ## When in proxy mode this section is used to specify further\r\n",
      "#   ## proxy address configurations.\r\n",
      "#   ## Remember to change host address to fit your environment.\r\n",
      "#   # [inputs.jolokia.proxy]\r\n",
      "#   #   host = \"127.0.0.1\"\r\n",
      "#   #   port = \"8080\"\r\n",
      "#\r\n",
      "#   ## Optional http timeouts\r\n",
      "#   ##\r\n",
      "#   ## response_header_timeout, if non-zero, specifies the amount of time to wait\r\n",
      "#   ## for a server's response headers after fully writing the request.\r\n",
      "#   # response_header_timeout = \"3s\"\r\n",
      "#   ##\r\n",
      "#   ## client_timeout specifies a time limit for requests made by this client.\r\n",
      "#   ## Includes connection time, any redirects, and reading the response body.\r\n",
      "#   # client_timeout = \"4s\"\r\n",
      "#\r\n",
      "#   ## Attribute delimiter\r\n",
      "#   ##\r\n",
      "#   ## When multiple attributes are returned for a single\r\n",
      "#   ## [inputs.jolokia.metrics], the field name is a concatenation of the metric\r\n",
      "#   ## name, and the attribute name, separated by the given delimiter.\r\n",
      "#   # delimiter = \"_\"\r\n",
      "#\r\n",
      "#   ## List of servers exposing jolokia read service\r\n",
      "#   [[inputs.jolokia.servers]]\r\n",
      "#     name = \"as-server-01\"\r\n",
      "#     host = \"127.0.0.1\"\r\n",
      "#     port = \"8080\"\r\n",
      "#     # username = \"myuser\"\r\n",
      "#     # password = \"mypassword\"\r\n",
      "#\r\n",
      "#   ## List of metrics collected on above servers\r\n",
      "#   ## Each metric consists in a name, a jmx path and either\r\n",
      "#   ## a pass or drop slice attribute.\r\n",
      "#   ##Â This collect all heap memory usage metrics.\r\n",
      "#   [[inputs.jolokia.metrics]]\r\n",
      "#     name = \"heap_memory_usage\"\r\n",
      "#     mbean  = \"java.lang:type=Memory\"\r\n",
      "#     attribute = \"HeapMemoryUsage\"\r\n",
      "#\r\n",
      "#   ##Â This collect thread counts metrics.\r\n",
      "#   [[inputs.jolokia.metrics]]\r\n",
      "#     name = \"thread_count\"\r\n",
      "#     mbean  = \"java.lang:type=Threading\"\r\n",
      "#     attribute = \"TotalStartedThreadCount,ThreadCount,DaemonThreadCount,PeakThreadCount\"\r\n",
      "#\r\n",
      "#   ##Â This collect number of class loaded/unloaded counts metrics.\r\n",
      "#   [[inputs.jolokia.metrics]]\r\n",
      "#     name = \"class_count\"\r\n",
      "#     mbean  = \"java.lang:type=ClassLoading\"\r\n",
      "#     attribute = \"LoadedClassCount,UnloadedClassCount,TotalLoadedClassCount\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read JMX metrics from a Jolokia REST agent endpoint\r\n",
      "# [[inputs.jolokia2_agent]]\r\n",
      "#   # default_tag_prefix      = \"\"\r\n",
      "#   # default_field_prefix    = \"\"\r\n",
      "#   # default_field_separator = \".\"\r\n",
      "#\r\n",
      "#   # Add agents URLs to query\r\n",
      "#   urls = [\"http://localhost:8080/jolokia\"]\r\n",
      "#   # username = \"\"\r\n",
      "#   # password = \"\"\r\n",
      "#   # response_timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS config\r\n",
      "#   # tls_ca   = \"/var/private/ca.pem\"\r\n",
      "#   # tls_cert = \"/var/private/client.pem\"\r\n",
      "#   # tls_key  = \"/var/private/client-key.pem\"\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Add metrics to read\r\n",
      "#   [[inputs.jolokia2_agent.metric]]\r\n",
      "#     name  = \"java_runtime\"\r\n",
      "#     mbean = \"java.lang:type=Runtime\"\r\n",
      "#     paths = [\"Uptime\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read JMX metrics from a Jolokia REST proxy endpoint\r\n",
      "# [[inputs.jolokia2_proxy]]\r\n",
      "#   # default_tag_prefix      = \"\"\r\n",
      "#   # default_field_prefix    = \"\"\r\n",
      "#   # default_field_separator = \".\"\r\n",
      "#\r\n",
      "#   ## Proxy agent\r\n",
      "#   url = \"http://localhost:8080/jolokia\"\r\n",
      "#   # username = \"\"\r\n",
      "#   # password = \"\"\r\n",
      "#   # response_timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS config\r\n",
      "#   # tls_ca   = \"/var/private/ca.pem\"\r\n",
      "#   # tls_cert = \"/var/private/client.pem\"\r\n",
      "#   # tls_key  = \"/var/private/client-key.pem\"\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Add proxy targets to query\r\n",
      "#   # default_target_username = \"\"\r\n",
      "#   # default_target_password = \"\"\r\n",
      "#   [[inputs.jolokia2_proxy.target]]\r\n",
      "#     url = \"service:jmx:rmi:///jndi/rmi://targethost:9999/jmxrmi\"\r\n",
      "#     # username = \"\"\r\n",
      "#     # password = \"\"\r\n",
      "#\r\n",
      "#   ## Add metrics to read\r\n",
      "#   [[inputs.jolokia2_proxy.metric]]\r\n",
      "#     name  = \"java_runtime\"\r\n",
      "#     mbean = \"java.lang:type=Runtime\"\r\n",
      "#     paths = [\"Uptime\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read Kapacitor-formatted JSON metrics from one or more HTTP endpoints\r\n",
      "# [[inputs.kapacitor]]\r\n",
      "#   ## Multiple URLs from which to read Kapacitor-formatted JSON\r\n",
      "#   ## Default is \"http://localhost:9092/kapacitor/v1/debug/vars\".\r\n",
      "#   urls = [\r\n",
      "#     \"http://localhost:9092/kapacitor/v1/debug/vars\"\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   ## Time limit for http requests\r\n",
      "#   timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Get kernel statistics from /proc/vmstat\r\n",
      "# [[inputs.kernel_vmstat]]\r\n",
      "#   # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from the kubernetes kubelet api\r\n",
      "# [[inputs.kubernetes]]\r\n",
      "#   ## URL for the kubelet\r\n",
      "#   url = \"http://1.1.1.1:10255\"\r\n",
      "#\r\n",
      "#   ## Use bearer token for authorization\r\n",
      "#   # bearer_token = /path/to/bearer/token\r\n",
      "#\r\n",
      "#   ## Set response_timeout (default 5 seconds)\r\n",
      "#   # response_timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = /path/to/cafile\r\n",
      "#   # tls_cert = /path/to/certfile\r\n",
      "#   # tls_key = /path/to/keyfile\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from a LeoFS Server via SNMP\r\n",
      "# [[inputs.leofs]]\r\n",
      "#   ## An array of URLs of the form:\r\n",
      "#   ##   host [ \":\" port]\r\n",
      "#   servers = [\"127.0.0.1:4020\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Provides Linux sysctl fs metrics\r\n",
      "# [[inputs.linux_sysctl_fs]]\r\n",
      "#   # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from local Lustre service on OST, MDS\r\n",
      "# [[inputs.lustre2]]\r\n",
      "#   ## An array of /proc globs to search for Lustre stats\r\n",
      "#   ## If not specified, the default will work on Lustre 2.5.x\r\n",
      "#   ##\r\n",
      "#   # ost_procfiles = [\r\n",
      "#   #   \"/proc/fs/lustre/obdfilter/*/stats\",\r\n",
      "#   #   \"/proc/fs/lustre/osd-ldiskfs/*/stats\",\r\n",
      "#   #   \"/proc/fs/lustre/obdfilter/*/job_stats\",\r\n",
      "#   # ]\r\n",
      "#   # mds_procfiles = [\r\n",
      "#   #   \"/proc/fs/lustre/mdt/*/md_stats\",\r\n",
      "#   #   \"/proc/fs/lustre/mdt/*/job_stats\",\r\n",
      "#   # ]\r\n",
      "\r\n",
      "\r\n",
      "# # Gathers metrics from the /3.0/reports MailChimp API\r\n",
      "# [[inputs.mailchimp]]\r\n",
      "#   ## MailChimp API key\r\n",
      "#   ## get from https://admin.mailchimp.com/account/api/\r\n",
      "#   api_key = \"\" # required\r\n",
      "#   ## Reports for campaigns sent more than days_old ago will not be collected.\r\n",
      "#   ## 0 means collect all.\r\n",
      "#   days_old = 0\r\n",
      "#   ## Campaign ID to get, if empty gets all campaigns, this option overrides days_old\r\n",
      "#   # campaign_id = \"\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many mcrouter servers\r\n",
      "# [[inputs.mcrouter]]\r\n",
      "#   ## An array of address to gather stats about. Specify an ip or hostname\r\n",
      "#   ## with port. ie tcp://localhost:11211, tcp://10.0.0.1:11211, etc.\r\n",
      "# \tservers = [\"tcp://localhost:11211\", \"unix:///var/run/mcrouter.sock\"]\r\n",
      "#\r\n",
      "# \t## Timeout for metric collections from all servers.  Minimum timeout is \"1s\".\r\n",
      "#   # timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many memcached servers\r\n",
      "# [[inputs.memcached]]\r\n",
      "#   ## An array of address to gather stats about. Specify an ip on hostname\r\n",
      "#   ## with optional port. ie localhost, 10.0.0.1:11211, etc.\r\n",
      "#   servers = [\"localhost:11211\"]\r\n",
      "#   # unix_sockets = [\"/var/run/memcached.sock\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Telegraf plugin for gathering metrics from N Mesos masters\r\n",
      "# [[inputs.mesos]]\r\n",
      "#   ## Timeout, in ms.\r\n",
      "#   timeout = 100\r\n",
      "#   ## A list of Mesos masters.\r\n",
      "#   masters = [\"http://localhost:5050\"]\r\n",
      "#   ## Master metrics groups to be collected, by default, all enabled.\r\n",
      "#   master_collections = [\r\n",
      "#     \"resources\",\r\n",
      "#     \"master\",\r\n",
      "#     \"system\",\r\n",
      "#     \"agents\",\r\n",
      "#     \"frameworks\",\r\n",
      "#     \"tasks\",\r\n",
      "#     \"messages\",\r\n",
      "#     \"evqueue\",\r\n",
      "#     \"registrar\",\r\n",
      "#   ]\r\n",
      "#   ## A list of Mesos slaves, default is []\r\n",
      "#   # slaves = []\r\n",
      "#   ## Slave metrics groups to be collected, by default, all enabled.\r\n",
      "#   # slave_collections = [\r\n",
      "#   #   \"resources\",\r\n",
      "#   #   \"agent\",\r\n",
      "#   #   \"system\",\r\n",
      "#   #   \"executors\",\r\n",
      "#   #   \"tasks\",\r\n",
      "#   #   \"messages\",\r\n",
      "#   # ]\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Collects scores from a minecraft server's scoreboard using the RCON protocol\r\n",
      "# [[inputs.minecraft]]\r\n",
      "#   ## server address for minecraft\r\n",
      "#   # server = \"localhost\"\r\n",
      "#   ## port for RCON\r\n",
      "#   # port = \"25575\"\r\n",
      "#   ## password RCON for mincraft server\r\n",
      "#   # password = \"\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many MongoDB servers\r\n",
      "# [[inputs.mongodb]]\r\n",
      "#   ## An array of URLs of the form:\r\n",
      "#   ##   \"mongodb://\" [user \":\" pass \"@\"] host [ \":\" port]\r\n",
      "#   ## For example:\r\n",
      "#   ##   mongodb://user:auth_key@10.10.3.30:27017,\r\n",
      "#   ##   mongodb://10.10.3.33:18832,\r\n",
      "#   servers = [\"mongodb://127.0.0.1:27017\"]\r\n",
      "#\r\n",
      "#   ## When true, collect per database stats\r\n",
      "#   # gather_perdb_stats = false\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many mysql servers\r\n",
      "# [[inputs.mysql]]\r\n",
      "#   ## specify servers via a url matching:\r\n",
      "#   ##  [username[:password]@][protocol[(address)]]/[?tls=[true|false|skip-verify|custom]]\r\n",
      "#   ##  see https://github.com/go-sql-driver/mysql#dsn-data-source-name\r\n",
      "#   ##  e.g.\r\n",
      "#   ##    servers = [\"user:passwd@tcp(127.0.0.1:3306)/?tls=false\"]\r\n",
      "#   ##    servers = [\"user@tcp(127.0.0.1:3306)/?tls=false\"]\r\n",
      "#   #\r\n",
      "#   ## If no servers are specified, then localhost is used as the host.\r\n",
      "#   servers = [\"tcp(127.0.0.1:3306)/\"]\r\n",
      "#\r\n",
      "#   ## Selects the metric output format.\r\n",
      "#   ##\r\n",
      "#   ## This option exists to maintain backwards compatibility, if you have\r\n",
      "#   ## existing metrics do not set or change this value until you are ready to\r\n",
      "#   ## migrate to the new format.\r\n",
      "#   ##\r\n",
      "#   ## If you do not have existing metrics from this plugin set to the latest\r\n",
      "#   ## version.\r\n",
      "#   ##\r\n",
      "#   ## Telegraf >=1.6: metric_version = 2\r\n",
      "#   ##           <1.6: metric_version = 1 (or unset)\r\n",
      "#   metric_version = 2\r\n",
      "#\r\n",
      "#   ## the limits for metrics form perf_events_statements\r\n",
      "#   perf_events_statements_digest_text_limit  = 120\r\n",
      "#   perf_events_statements_limit              = 250\r\n",
      "#   perf_events_statements_time_limit         = 86400\r\n",
      "#   #\r\n",
      "#   ## if the list is empty, then metrics are gathered from all databasee tables\r\n",
      "#   table_schema_databases                    = []\r\n",
      "#   #\r\n",
      "#   ## gather metrics from INFORMATION_SCHEMA.TABLES for databases provided above list\r\n",
      "#   gather_table_schema                       = false\r\n",
      "#   #\r\n",
      "#   ## gather thread state counts from INFORMATION_SCHEMA.PROCESSLIST\r\n",
      "#   gather_process_list                       = true\r\n",
      "#   #\r\n",
      "#   ## gather thread state counts from INFORMATION_SCHEMA.USER_STATISTICS\r\n",
      "#   gather_user_statistics                    = true\r\n",
      "#   #\r\n",
      "#   ## gather auto_increment columns and max values from information schema\r\n",
      "#   gather_info_schema_auto_inc               = true\r\n",
      "#   #\r\n",
      "#   ## gather metrics from INFORMATION_SCHEMA.INNODB_METRICS\r\n",
      "#   gather_innodb_metrics                     = true\r\n",
      "#   #\r\n",
      "#   ## gather metrics from SHOW SLAVE STATUS command output\r\n",
      "#   gather_slave_status                       = true\r\n",
      "#   #\r\n",
      "#   ## gather metrics from SHOW BINARY LOGS command output\r\n",
      "#   gather_binary_logs                        = false\r\n",
      "#   #\r\n",
      "#   ## gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_TABLE\r\n",
      "#   gather_table_io_waits                     = false\r\n",
      "#   #\r\n",
      "#   ## gather metrics from PERFORMANCE_SCHEMA.TABLE_LOCK_WAITS\r\n",
      "#   gather_table_lock_waits                   = false\r\n",
      "#   #\r\n",
      "#   ## gather metrics from PERFORMANCE_SCHEMA.TABLE_IO_WAITS_SUMMARY_BY_INDEX_USAGE\r\n",
      "#   gather_index_io_waits                     = false\r\n",
      "#   #\r\n",
      "#   ## gather metrics from PERFORMANCE_SCHEMA.EVENT_WAITS\r\n",
      "#   gather_event_waits                        = false\r\n",
      "#   #\r\n",
      "#   ## gather metrics from PERFORMANCE_SCHEMA.FILE_SUMMARY_BY_EVENT_NAME\r\n",
      "#   gather_file_events_stats                  = false\r\n",
      "#   #\r\n",
      "#   ## gather metrics from PERFORMANCE_SCHEMA.EVENTS_STATEMENTS_SUMMARY_BY_DIGEST\r\n",
      "#   gather_perf_events_statements             = false\r\n",
      "#   #\r\n",
      "#   ## Some queries we may want to run less often (such as SHOW GLOBAL VARIABLES)\r\n",
      "#   interval_slow                   = \"30m\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config (will be used if tls=custom parameter specified in server uri)\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Provides metrics about the state of a NATS server\r\n",
      "# [[inputs.nats]]\r\n",
      "#   ## The address of the monitoring endpoint of the NATS server\r\n",
      "#   server = \"http://localhost:8222\"\r\n",
      "#\r\n",
      "#   ## Maximum time to receive response\r\n",
      "#   # response_timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics about network interface usage\r\n",
      "# [[inputs.net]]\r\n",
      "#   ## By default, telegraf gathers stats from any up interface (excluding loopback)\r\n",
      "#   ## Setting interfaces will tell it to gather these explicit interfaces,\r\n",
      "#   ## regardless of status.\r\n",
      "#   ##\r\n",
      "#   # interfaces = [\"eth0\"]\r\n",
      "#   ##\r\n",
      "#   ## On linux systems telegraf also collects protocol stats.\r\n",
      "#   ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.\r\n",
      "#   ##\r\n",
      "#   # ignore_protocol_stats = false\r\n",
      "#   ##\r\n",
      "\r\n",
      "\r\n",
      "# # Collect response time of a TCP or UDP connection\r\n",
      "# [[inputs.net_response]]\r\n",
      "#   ## Protocol, must be \"tcp\" or \"udp\"\r\n",
      "#   ## NOTE: because the \"udp\" protocol does not respond to requests, it requires\r\n",
      "#   ## a send/expect string pair (see below).\r\n",
      "#   protocol = \"tcp\"\r\n",
      "#   ## Server address (default localhost)\r\n",
      "#   address = \"localhost:80\"\r\n",
      "#\r\n",
      "#   ## Set timeout\r\n",
      "#   # timeout = \"1s\"\r\n",
      "#\r\n",
      "#   ## Set read timeout (only used if expecting a response)\r\n",
      "#   # read_timeout = \"1s\"\r\n",
      "#\r\n",
      "#   ## The following options are required for UDP checks. For TCP, they are\r\n",
      "#   ## optional. The plugin will send the given string to the server and then\r\n",
      "#   ## expect to receive the given 'expect' string back.\r\n",
      "#   ## string sent to the server\r\n",
      "#   # send = \"ssh\"\r\n",
      "#   ## expected string in answer\r\n",
      "#   # expect = \"ssh\"\r\n",
      "#\r\n",
      "#   ## Uncomment to remove deprecated fields\r\n",
      "#   # fieldexclude = [\"result_type\", \"string_found\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read TCP metrics such as established, time wait and sockets counts.\r\n",
      "# [[inputs.netstat]]\r\n",
      "#   # no configuration\r\n",
      "\r\n",
      "\r\n",
      "# # Read Nginx's basic status information (ngx_http_stub_status_module)\r\n",
      "# [[inputs.nginx]]\r\n",
      "#   # An array of Nginx stub_status URI to gather stats.\r\n",
      "#   urls = [\"http://localhost/server_status\"]\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   tls_cert = \"/etc/telegraf/cert.cer\"\r\n",
      "#   tls_key = \"/etc/telegraf/key.key\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   # HTTP response timeout (default: 5s)\r\n",
      "#   response_timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read Nginx Plus' full status information (ngx_http_status_module)\r\n",
      "# [[inputs.nginx_plus]]\r\n",
      "#   ## An array of ngx_http_status_module or status URI to gather stats.\r\n",
      "#   urls = [\"http://localhost/status\"]\r\n",
      "#\r\n",
      "#   # HTTP response timeout (default: 5s)\r\n",
      "#   response_timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read NSQ topic and channel statistics.\r\n",
      "# [[inputs.nsq]]\r\n",
      "#   ## An array of NSQD HTTP API endpoints\r\n",
      "#   endpoints = [\"http://localhost:4151\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Collect kernel snmp counters and network interface statistics\r\n",
      "# [[inputs.nstat]]\r\n",
      "#   ## file paths for proc files. If empty default paths will be used:\r\n",
      "#   ##    /proc/net/netstat, /proc/net/snmp, /proc/net/snmp6\r\n",
      "#   ## These can also be overridden with env variables, see README.\r\n",
      "#   proc_net_netstat = \"/proc/net/netstat\"\r\n",
      "#   proc_net_snmp = \"/proc/net/snmp\"\r\n",
      "#   proc_net_snmp6 = \"/proc/net/snmp6\"\r\n",
      "#   ## dump metrics with 0 values too\r\n",
      "#   dump_zeros       = true\r\n",
      "\r\n",
      "\r\n",
      "# # Get standard NTP query metrics, requires ntpq executable.\r\n",
      "# [[inputs.ntpq]]\r\n",
      "#   ## If false, set the -n ntpq flag. Can reduce metric gather time.\r\n",
      "#   dns_lookup = true\r\n",
      "\r\n",
      "\r\n",
      "# # Pulls statistics from nvidia GPUs attached to the host\r\n",
      "# [[inputs.nvidia_smi]]\r\n",
      "# ## Optional: path to nvidia-smi binary, defaults to $PATH via exec.LookPath\r\n",
      "# # bin_path = /usr/bin/nvidia-smi\r\n",
      "#\r\n",
      "# ## Optional: timeout for GPU polling\r\n",
      "# # timeout = 5s\r\n",
      "\r\n",
      "\r\n",
      "# # OpenLDAP cn=Monitor plugin\r\n",
      "# [[inputs.openldap]]\r\n",
      "#   host = \"localhost\"\r\n",
      "#   port = 389\r\n",
      "#\r\n",
      "#   # ldaps, starttls, or no encryption. default is an empty string, disabling all encryption.\r\n",
      "#   # note that port will likely need to be changed to 636 for ldaps\r\n",
      "#   # valid options: \"\" | \"starttls\" | \"ldaps\"\r\n",
      "#   ssl = \"\"\r\n",
      "#\r\n",
      "#   # skip peer certificate verification. Default is false.\r\n",
      "#   insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   # Path to PEM-encoded Root certificate to use to verify server certificate\r\n",
      "#   tls_ca = \"/etc/ssl/certs.pem\"\r\n",
      "#\r\n",
      "#   # dn/password to bind with. If bind_dn is empty, an anonymous bind is performed.\r\n",
      "#   bind_dn = \"\"\r\n",
      "#   bind_password = \"\"\r\n",
      "#\r\n",
      "#   # Reverse metric names so they sort more naturally. Recommended.\r\n",
      "#   # This defaults to false if unset, but is set to true when generating a new config\r\n",
      "#   reverse_metric_names = true\r\n",
      "\r\n",
      "\r\n",
      "# # A plugin to collect stats from Opensmtpd - a validating, recursive, and caching DNS resolver \r\n",
      "# [[inputs.opensmtpd]]\r\n",
      "#   ## If running as a restricted user you can prepend sudo for additional access:\r\n",
      "#   #use_sudo = false\r\n",
      "#\r\n",
      "#   ## The default location of the smtpctl binary can be overridden with:\r\n",
      "#   binary = \"/usr/sbin/smtpctl\"\r\n",
      "#\r\n",
      "#   ## The default timeout of 1000ms can be overriden with (in milliseconds):\r\n",
      "#   timeout = 1000\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics of passenger using passenger-status\r\n",
      "# [[inputs.passenger]]\r\n",
      "#   ## Path of passenger-status.\r\n",
      "#   ##\r\n",
      "#   ## Plugin gather metric via parsing XML output of passenger-status\r\n",
      "#   ## More information about the tool:\r\n",
      "#   ##   https://www.phusionpassenger.com/library/admin/apache/overall_status_report.html\r\n",
      "#   ##\r\n",
      "#   ## If no path is specified, then the plugin simply execute passenger-status\r\n",
      "#   ## hopefully it can be found in your PATH\r\n",
      "#   command = \"passenger-status -v --show=xml\"\r\n",
      "\r\n",
      "\r\n",
      "# # Gather counters from PF\r\n",
      "# [[inputs.pf]]\r\n",
      "#   ## PF require root access on most systems.\r\n",
      "#   ## Setting 'use_sudo' to true will make use of sudo to run pfctl.\r\n",
      "#   ## Users must configure sudo to allow telegraf user to run pfctl with no password.\r\n",
      "#   ## pfctl can be restricted to only list command \"pfctl -s info\".\r\n",
      "#   use_sudo = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics of phpfpm, via HTTP status page or socket\r\n",
      "# [[inputs.phpfpm]]\r\n",
      "#   ## An array of addresses to gather stats about. Specify an ip or hostname\r\n",
      "#   ## with optional port and path\r\n",
      "#   ##\r\n",
      "#   ## Plugin can be configured in three modes (either can be used):\r\n",
      "#   ##   - http: the URL must start with http:// or https://, ie:\r\n",
      "#   ##       \"http://localhost/status\"\r\n",
      "#   ##       \"http://192.168.130.1/status?full\"\r\n",
      "#   ##\r\n",
      "#   ##   - unixsocket: path to fpm socket, ie:\r\n",
      "#   ##       \"/var/run/php5-fpm.sock\"\r\n",
      "#   ##      or using a custom fpm status path:\r\n",
      "#   ##       \"/var/run/php5-fpm.sock:fpm-custom-status-path\"\r\n",
      "#   ##\r\n",
      "#   ##   - fcgi: the URL must start with fcgi:// or cgi://, and port must be present, ie:\r\n",
      "#   ##       \"fcgi://10.0.0.12:9000/status\"\r\n",
      "#   ##       \"cgi://10.0.10.12:9001/status\"\r\n",
      "#   ##\r\n",
      "#   ## Example of multiple gathering from local socket and remove host\r\n",
      "#   ## urls = [\"http://192.168.1.20/status\", \"/tmp/fpm.sock\"]\r\n",
      "#   urls = [\"http://localhost/status\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Ping given url(s) and return statistics\r\n",
      "# [[inputs.ping]]\r\n",
      "#   ## NOTE: this plugin forks the ping command. You may need to set capabilities\r\n",
      "#   ## via setcap cap_net_raw+p /bin/ping\r\n",
      "#   #\r\n",
      "#   ## List of urls to ping\r\n",
      "#   urls = [\"www.google.com\"] # required\r\n",
      "#   ## number of pings to send per collection (ping -c <COUNT>)\r\n",
      "#   # count = 1\r\n",
      "#   ## interval, in s, at which to ping. 0 == default (ping -i <PING_INTERVAL>)\r\n",
      "#   # ping_interval = 1.0\r\n",
      "#   ## per-ping timeout, in s. 0 == no timeout (ping -W <TIMEOUT>)\r\n",
      "#   # timeout = 1.0\r\n",
      "#   ## total-ping deadline, in s. 0 == no deadline (ping -w <DEADLINE>)\r\n",
      "#   # deadline = 10\r\n",
      "#   ## interface or source address to send ping from (ping -I <INTERFACE/SRC_ADDR>)\r\n",
      "#   ## on Darwin and Freebsd only source address possible: (ping -S <SRC_ADDR>)\r\n",
      "#   # interface = \"\"\r\n",
      "\r\n",
      "\r\n",
      "# # Measure postfix queue statistics\r\n",
      "# [[inputs.postfix]]\r\n",
      "#   ## Postfix queue directory. If not provided, telegraf will try to use\r\n",
      "#   ## 'postconf -h queue_directory' to determine it.\r\n",
      "#   # queue_directory = \"/var/spool/postfix\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many PowerDNS servers\r\n",
      "# [[inputs.powerdns]]\r\n",
      "#   ## An array of sockets to gather stats about.\r\n",
      "#   ## Specify a path to unix socket.\r\n",
      "#   unix_sockets = [\"/var/run/pdns.controlsocket\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Monitor process cpu and memory usage\r\n",
      "# [[inputs.procstat]]\r\n",
      "#   ## PID file to monitor process\r\n",
      "#   pid_file = \"/var/run/nginx.pid\"\r\n",
      "#   ## executable name (ie, pgrep <exe>)\r\n",
      "#   # exe = \"nginx\"\r\n",
      "#   ## pattern as argument for pgrep (ie, pgrep -f <pattern>)\r\n",
      "#   # pattern = \"nginx\"\r\n",
      "#   ## user as argument for pgrep (ie, pgrep -u <user>)\r\n",
      "#   # user = \"nginx\"\r\n",
      "#   ## Systemd unit name\r\n",
      "#   # systemd_unit = \"nginx.service\"\r\n",
      "#   ## CGroup name or path\r\n",
      "#   # cgroup = \"systemd/system.slice/nginx.service\"\r\n",
      "#\r\n",
      "#   ## override for process_name\r\n",
      "#   ## This is optional; default is sourced from /proc/<pid>/status\r\n",
      "#   # process_name = \"bar\"\r\n",
      "#\r\n",
      "#   ## Field name prefix\r\n",
      "#   # prefix = \"\"\r\n",
      "#\r\n",
      "#   ## Add PID as a tag instead of a field; useful to differentiate between\r\n",
      "#   ## processes whose tags are otherwise the same.  Can create a large number\r\n",
      "#   ## of series, use judiciously.\r\n",
      "#   # pid_tag = false\r\n",
      "#\r\n",
      "#   ## Method to use when finding process IDs.  Can be one of 'pgrep', or\r\n",
      "#   ## 'native'.  The pgrep finder calls the pgrep executable in the PATH while\r\n",
      "#   ## the native finder performs the search directly in a manor dependent on the\r\n",
      "#   ## platform.  Default is 'pgrep'\r\n",
      "#   # pid_finder = \"pgrep\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many prometheus clients\r\n",
      "# [[inputs.prometheus]]\r\n",
      "#   ## An array of urls to scrape metrics from.\r\n",
      "#   urls = [\"http://localhost:9100/metrics\"]\r\n",
      "#\r\n",
      "#   ## An array of Kubernetes services to scrape metrics from.\r\n",
      "#   # kubernetes_services = [\"http://my-service-dns.my-namespace:9100/metrics\"]\r\n",
      "#\r\n",
      "#   ## Use bearer token for authorization\r\n",
      "#   # bearer_token = /path/to/bearer/token\r\n",
      "#\r\n",
      "#   ## Specify timeout duration for slower prometheus clients (default is 3s)\r\n",
      "#   # response_timeout = \"3s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = /path/to/cafile\r\n",
      "#   # tls_cert = /path/to/certfile\r\n",
      "#   # tls_key = /path/to/keyfile\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Reads last_run_summary.yaml file and converts to measurments\r\n",
      "# [[inputs.puppetagent]]\r\n",
      "#   ## Location of puppet last run summary file\r\n",
      "#   location = \"/var/lib/puppet/state/last_run_summary.yaml\"\r\n",
      "\r\n",
      "\r\n",
      "# # Reads metrics from RabbitMQ servers via the Management Plugin\r\n",
      "# [[inputs.rabbitmq]]\r\n",
      "#   ## Management Plugin url. (default: http://localhost:15672)\r\n",
      "#   # url = \"http://localhost:15672\"\r\n",
      "#   ## Tag added to rabbitmq_overview series; deprecated: use tags\r\n",
      "#   # name = \"rmq-server-1\"\r\n",
      "#   ## Credentials\r\n",
      "#   # username = \"guest\"\r\n",
      "#   # password = \"guest\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Optional request timeouts\r\n",
      "#   ##\r\n",
      "#   ## ResponseHeaderTimeout, if non-zero, specifies the amount of time to wait\r\n",
      "#   ## for a server's response headers after fully writing the request.\r\n",
      "#   # header_timeout = \"3s\"\r\n",
      "#   ##\r\n",
      "#   ## client_timeout specifies a time limit for requests made by this client.\r\n",
      "#   ## Includes connection time, any redirects, and reading the response body.\r\n",
      "#   # client_timeout = \"4s\"\r\n",
      "#\r\n",
      "#   ## A list of nodes to gather as the rabbitmq_node measurement. If not\r\n",
      "#   ## specified, metrics for all nodes are gathered.\r\n",
      "#   # nodes = [\"rabbit@node1\", \"rabbit@node2\"]\r\n",
      "#\r\n",
      "#   ## A list of queues to gather as the rabbitmq_queue measurement. If not\r\n",
      "#   ## specified, metrics for all queues are gathered.\r\n",
      "#   # queues = [\"telegraf\"]\r\n",
      "#\r\n",
      "#   ## A list of exchanges to gather as the rabbitmq_exchange measurement. If not\r\n",
      "#   ## specified, metrics for all exchanges are gathered.\r\n",
      "#   # exchanges = [\"telegraf\"]\r\n",
      "#\r\n",
      "#   ## Queues to include and exclude. Globs accepted.\r\n",
      "#   ## Note that an empty array for both will include all queues\r\n",
      "#   queue_name_include = []\r\n",
      "#   queue_name_exclude = []\r\n",
      "\r\n",
      "\r\n",
      "# # Read raindrops stats (raindrops - real-time stats for preforking Rack servers)\r\n",
      "# [[inputs.raindrops]]\r\n",
      "#   ## An array of raindrops middleware URI to gather stats.\r\n",
      "#   urls = [\"http://localhost:8080/_raindrops\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many redis servers\r\n",
      "# [[inputs.redis]]\r\n",
      "#   ## specify servers via a url matching:\r\n",
      "#   ##  [protocol://][:password]@address[:port]\r\n",
      "#   ##  e.g.\r\n",
      "#   ##    tcp://localhost:6379\r\n",
      "#   ##    tcp://:password@192.168.99.100\r\n",
      "#   ##    unix:///var/run/redis.sock\r\n",
      "#   ##\r\n",
      "#   ## If no servers are specified, then localhost is used as the host.\r\n",
      "#   ## If no port is specified, 6379 is used\r\n",
      "#   servers = [\"tcp://localhost:6379\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many RethinkDB servers\r\n",
      "# [[inputs.rethinkdb]]\r\n",
      "#   ## An array of URI to gather stats about. Specify an ip or hostname\r\n",
      "#   ## with optional port add password. ie,\r\n",
      "#   ##   rethinkdb://user:auth_key@10.10.3.30:28105,\r\n",
      "#   ##   rethinkdb://10.10.3.33:18832,\r\n",
      "#   ##   10.0.0.1:10000, etc.\r\n",
      "#   servers = [\"127.0.0.1:28015\"]\r\n",
      "#   ##\r\n",
      "#   ## If you use actual rethinkdb of > 2.3.0 with username/password authorization,\r\n",
      "#   ## protocol have to be named \"rethinkdb2\" - it will use 1_0 H.\r\n",
      "#   # servers = [\"rethinkdb2://username:password@127.0.0.1:28015\"]\r\n",
      "#   ##\r\n",
      "#   ## If you use older versions of rethinkdb (<2.2) with auth_key, protocol\r\n",
      "#   ## have to be named \"rethinkdb\".\r\n",
      "#   # servers = [\"rethinkdb://username:auth_key@127.0.0.1:28015\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics one or many Riak servers\r\n",
      "# [[inputs.riak]]\r\n",
      "#   # Specify a list of one or more riak http servers\r\n",
      "#   servers = [\"http://localhost:8098\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read API usage and limits for a Salesforce organisation\r\n",
      "# [[inputs.salesforce]]\r\n",
      "#   ## specify your credentials\r\n",
      "#   ##\r\n",
      "#   username = \"your_username\"\r\n",
      "#   password = \"your_password\"\r\n",
      "#   ##\r\n",
      "#   ## (optional) security token\r\n",
      "#   # security_token = \"your_security_token\"\r\n",
      "#   ##\r\n",
      "#   ## (optional) environment type (sandbox or production)\r\n",
      "#   ## default is: production\r\n",
      "#   ##\r\n",
      "#   # environment = \"production\"\r\n",
      "#   ##\r\n",
      "#   ## (optional) API version (default: \"39.0\")\r\n",
      "#   ##\r\n",
      "#   # version = \"39.0\"\r\n",
      "\r\n",
      "\r\n",
      "# # Monitor sensors, requires lm-sensors package\r\n",
      "# [[inputs.sensors]]\r\n",
      "#   ## Remove numbers from field names.\r\n",
      "#   ## If true, a field name like 'temp1_input' will be changed to 'temp_input'.\r\n",
      "#   # remove_numbers = true\r\n",
      "#\r\n",
      "#   ## Timeout is the maximum amount of time that the sensors command can run.\r\n",
      "#   # timeout = \"5s\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from storage devices supporting S.M.A.R.T.\r\n",
      "# [[inputs.smart]]\r\n",
      "#   ## Optionally specify the path to the smartctl executable\r\n",
      "#   # path = \"/usr/bin/smartctl\"\r\n",
      "#   #\r\n",
      "#   ## On most platforms smartctl requires root access.\r\n",
      "#   ## Setting 'use_sudo' to true will make use of sudo to run smartctl.\r\n",
      "#   ## Sudo must be configured to to allow the telegraf user to run smartctl\r\n",
      "#   ## with out password.\r\n",
      "#   # use_sudo = false\r\n",
      "#   #\r\n",
      "#   ## Skip checking disks in this power mode. Defaults to\r\n",
      "#   ## \"standby\" to not wake up disks that have stoped rotating.\r\n",
      "#   ## See --nocheck in the man pages for smartctl.\r\n",
      "#   ## smartctl version 5.41 and 5.42 have faulty detection of\r\n",
      "#   ## power mode and might require changing this value to\r\n",
      "#   ## \"never\" depending on your disks.\r\n",
      "#   # nocheck = \"standby\"\r\n",
      "#   #\r\n",
      "#   ## Gather detailed metrics for each SMART Attribute.\r\n",
      "#   ## Defaults to \"false\"\r\n",
      "#   ##\r\n",
      "#   # attributes = false\r\n",
      "#   #\r\n",
      "#   ## Optionally specify devices to exclude from reporting.\r\n",
      "#   # excludes = [ \"/dev/pass6\" ]\r\n",
      "#   #\r\n",
      "#   ## Optionally specify devices and device type, if unset\r\n",
      "#   ## a scan (smartctl --scan) for S.M.A.R.T. devices will\r\n",
      "#   ## done and all found will be included except for the\r\n",
      "#   ## excluded in excludes.\r\n",
      "#   # devices = [ \"/dev/ada0 -d atacam\" ]\r\n",
      "\r\n",
      "\r\n",
      "# # Retrieves SNMP values from remote agents\r\n",
      "# [[inputs.snmp]]\r\n",
      "#   agents = [ \"127.0.0.1:161\" ]\r\n",
      "#   ## Timeout for each SNMP query.\r\n",
      "#   timeout = \"5s\"\r\n",
      "#   ## Number of retries to attempt within timeout.\r\n",
      "#   retries = 3\r\n",
      "#   ## SNMP version, values can be 1, 2, or 3\r\n",
      "#   version = 2\r\n",
      "#\r\n",
      "#   ## SNMP community string.\r\n",
      "#   community = \"public\"\r\n",
      "#\r\n",
      "#   ## The GETBULK max-repetitions parameter\r\n",
      "#   max_repetitions = 10\r\n",
      "#\r\n",
      "#   ## SNMPv3 auth parameters\r\n",
      "#   #sec_name = \"myuser\"\r\n",
      "#   #auth_protocol = \"md5\"      # Values: \"MD5\", \"SHA\", \"\"\r\n",
      "#   #auth_password = \"pass\"\r\n",
      "#   #sec_level = \"authNoPriv\"   # Values: \"noAuthNoPriv\", \"authNoPriv\", \"authPriv\"\r\n",
      "#   #context_name = \"\"\r\n",
      "#   #priv_protocol = \"\"         # Values: \"DES\", \"AES\", \"\"\r\n",
      "#   #priv_password = \"\"\r\n",
      "#\r\n",
      "#   ## measurement name\r\n",
      "#   name = \"system\"\r\n",
      "#   [[inputs.snmp.field]]\r\n",
      "#     name = \"hostname\"\r\n",
      "#     oid = \".1.0.0.1.1\"\r\n",
      "#   [[inputs.snmp.field]]\r\n",
      "#     name = \"uptime\"\r\n",
      "#     oid = \".1.0.0.1.2\"\r\n",
      "#   [[inputs.snmp.field]]\r\n",
      "#     name = \"load\"\r\n",
      "#     oid = \".1.0.0.1.3\"\r\n",
      "#   [[inputs.snmp.field]]\r\n",
      "#     oid = \"HOST-RESOURCES-MIB::hrMemorySize\"\r\n",
      "#\r\n",
      "#   [[inputs.snmp.table]]\r\n",
      "#     ## measurement name\r\n",
      "#     name = \"remote_servers\"\r\n",
      "#     inherit_tags = [ \"hostname\" ]\r\n",
      "#     [[inputs.snmp.table.field]]\r\n",
      "#       name = \"server\"\r\n",
      "#       oid = \".1.0.0.0.1.0\"\r\n",
      "#       is_tag = true\r\n",
      "#     [[inputs.snmp.table.field]]\r\n",
      "#       name = \"connections\"\r\n",
      "#       oid = \".1.0.0.0.1.1\"\r\n",
      "#     [[inputs.snmp.table.field]]\r\n",
      "#       name = \"latency\"\r\n",
      "#       oid = \".1.0.0.0.1.2\"\r\n",
      "#\r\n",
      "#   [[inputs.snmp.table]]\r\n",
      "#     ## auto populate table's fields using the MIB\r\n",
      "#     oid = \"HOST-RESOURCES-MIB::hrNetworkTable\"\r\n",
      "\r\n",
      "\r\n",
      "# # DEPRECATED! PLEASE USE inputs.snmp INSTEAD.\r\n",
      "# [[inputs.snmp_legacy]]\r\n",
      "#   ## Use 'oids.txt' file to translate oids to names\r\n",
      "#   ## To generate 'oids.txt' you need to run:\r\n",
      "#   ##   snmptranslate -m all -Tz -On | sed -e 's/\"//g' > /tmp/oids.txt\r\n",
      "#   ## Or if you have an other MIB folder with custom MIBs\r\n",
      "#   ##   snmptranslate -M /mycustommibfolder -Tz -On -m all | sed -e 's/\"//g' > oids.txt\r\n",
      "#   snmptranslate_file = \"/tmp/oids.txt\"\r\n",
      "#   [[inputs.snmp.host]]\r\n",
      "#     address = \"192.168.2.2:161\"\r\n",
      "#     # SNMP community\r\n",
      "#     community = \"public\" # default public\r\n",
      "#     # SNMP version (1, 2 or 3)\r\n",
      "#     # Version 3 not supported yet\r\n",
      "#     version = 2 # default 2\r\n",
      "#     # SNMP response timeout\r\n",
      "#     timeout = 2.0 # default 2.0\r\n",
      "#     # SNMP request retries\r\n",
      "#     retries = 2 # default 2\r\n",
      "#     # Which get/bulk do you want to collect for this host\r\n",
      "#     collect = [\"mybulk\", \"sysservices\", \"sysdescr\"]\r\n",
      "#     # Simple list of OIDs to get, in addition to \"collect\"\r\n",
      "#     get_oids = []\r\n",
      "#\r\n",
      "#   [[inputs.snmp.host]]\r\n",
      "#     address = \"192.168.2.3:161\"\r\n",
      "#     community = \"public\"\r\n",
      "#     version = 2\r\n",
      "#     timeout = 2.0\r\n",
      "#     retries = 2\r\n",
      "#     collect = [\"mybulk\"]\r\n",
      "#     get_oids = [\r\n",
      "#         \"ifNumber\",\r\n",
      "#         \".1.3.6.1.2.1.1.3.0\",\r\n",
      "#     ]\r\n",
      "#\r\n",
      "#   [[inputs.snmp.get]]\r\n",
      "#     name = \"ifnumber\"\r\n",
      "#     oid = \"ifNumber\"\r\n",
      "#\r\n",
      "#   [[inputs.snmp.get]]\r\n",
      "#     name = \"interface_speed\"\r\n",
      "#     oid = \"ifSpeed\"\r\n",
      "#     instance = \"0\"\r\n",
      "#\r\n",
      "#   [[inputs.snmp.get]]\r\n",
      "#     name = \"sysuptime\"\r\n",
      "#     oid = \".1.3.6.1.2.1.1.3.0\"\r\n",
      "#     unit = \"second\"\r\n",
      "#\r\n",
      "#   [[inputs.snmp.bulk]]\r\n",
      "#     name = \"mybulk\"\r\n",
      "#     max_repetition = 127\r\n",
      "#     oid = \".1.3.6.1.2.1.1\"\r\n",
      "#\r\n",
      "#   [[inputs.snmp.bulk]]\r\n",
      "#     name = \"ifoutoctets\"\r\n",
      "#     max_repetition = 127\r\n",
      "#     oid = \"ifOutOctets\"\r\n",
      "#\r\n",
      "#   [[inputs.snmp.host]]\r\n",
      "#     address = \"192.168.2.13:161\"\r\n",
      "#     #address = \"127.0.0.1:161\"\r\n",
      "#     community = \"public\"\r\n",
      "#     version = 2\r\n",
      "#     timeout = 2.0\r\n",
      "#     retries = 2\r\n",
      "#     #collect = [\"mybulk\", \"sysservices\", \"sysdescr\", \"systype\"]\r\n",
      "#     collect = [\"sysuptime\" ]\r\n",
      "#     [[inputs.snmp.host.table]]\r\n",
      "#       name = \"iftable3\"\r\n",
      "#       include_instances = [\"enp5s0\", \"eth1\"]\r\n",
      "#\r\n",
      "#   # SNMP TABLEs\r\n",
      "#   # table without mapping neither subtables\r\n",
      "#   [[inputs.snmp.table]]\r\n",
      "#     name = \"iftable1\"\r\n",
      "#     oid = \".1.3.6.1.2.1.31.1.1.1\"\r\n",
      "#\r\n",
      "#   # table without mapping but with subtables\r\n",
      "#   [[inputs.snmp.table]]\r\n",
      "#     name = \"iftable2\"\r\n",
      "#     oid = \".1.3.6.1.2.1.31.1.1.1\"\r\n",
      "#     sub_tables = [\".1.3.6.1.2.1.2.2.1.13\"]\r\n",
      "#\r\n",
      "#   # table with mapping but without subtables\r\n",
      "#   [[inputs.snmp.table]]\r\n",
      "#     name = \"iftable3\"\r\n",
      "#     oid = \".1.3.6.1.2.1.31.1.1.1\"\r\n",
      "#     # if empty. get all instances\r\n",
      "#     mapping_table = \".1.3.6.1.2.1.31.1.1.1.1\"\r\n",
      "#     # if empty, get all subtables\r\n",
      "#\r\n",
      "#   # table with both mapping and subtables\r\n",
      "#   [[inputs.snmp.table]]\r\n",
      "#     name = \"iftable4\"\r\n",
      "#     oid = \".1.3.6.1.2.1.31.1.1.1\"\r\n",
      "#     # if empty get all instances\r\n",
      "#     mapping_table = \".1.3.6.1.2.1.31.1.1.1.1\"\r\n",
      "#     # if empty get all subtables\r\n",
      "#     # sub_tables could be not \"real subtables\"\r\n",
      "#     sub_tables=[\".1.3.6.1.2.1.2.2.1.13\", \"bytes_recv\", \"bytes_send\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read stats from one or more Solr servers or cores\r\n",
      "# [[inputs.solr]]\r\n",
      "#   ## specify a list of one or more Solr servers\r\n",
      "#   servers = [\"http://localhost:8983\"]\r\n",
      "#\r\n",
      "#   ## specify a list of one or more Solr cores (default - all)\r\n",
      "#   # cores = [\"main\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from Microsoft SQL Server\r\n",
      "# [[inputs.sqlserver]]\r\n",
      "#   ## Specify instances to monitor with a list of connection strings.\r\n",
      "#   ## All connection parameters are optional.\r\n",
      "#   ## By default, the host is localhost, listening on default port, TCP 1433.\r\n",
      "#   ##   for Windows, the user is the currently running AD user (SSO).\r\n",
      "#   ##   See https://github.com/denisenkom/go-mssqldb for detailed connection\r\n",
      "#   ##   parameters.\r\n",
      "#   # servers = [\r\n",
      "#   #  \"Server=192.168.1.10;Port=1433;User Id=<user>;Password=<pw>;app name=telegraf;log=1;\",\r\n",
      "#   # ]\r\n",
      "#\r\n",
      "#   ## Optional parameter, setting this to 2 will use a new version\r\n",
      "#   ## of the collection queries that break compatibility with the original\r\n",
      "#   ## dashboards.\r\n",
      "#   query_version = 2\r\n",
      "#\r\n",
      "#   ## If you are using AzureDB, setting this to true will gather resource utilization metrics\r\n",
      "#   # azuredb = false\r\n",
      "#\r\n",
      "#   ## If you would like to exclude some of the metrics queries, list them here\r\n",
      "#   ## Possible choices:\r\n",
      "#   ## - PerformanceCounters\r\n",
      "#   ## - WaitStatsCategorized\r\n",
      "#   ## - DatabaseIO\r\n",
      "#   ## - DatabaseProperties\r\n",
      "#   ## - CPUHistory\r\n",
      "#   ## - DatabaseSize\r\n",
      "#   ## - DatabaseStats\r\n",
      "#   ## - MemoryClerk\r\n",
      "#   ## - VolumeSpace\r\n",
      "#   ## - PerformanceMetrics\r\n",
      "#   # exclude_query = [ 'DatabaseIO' ]\r\n",
      "\r\n",
      "\r\n",
      "# # Sysstat metrics collector\r\n",
      "# [[inputs.sysstat]]\r\n",
      "#   ## Path to the sadc command.\r\n",
      "#   #\r\n",
      "#   ## Common Defaults:\r\n",
      "#   ##   Debian/Ubuntu: /usr/lib/sysstat/sadc\r\n",
      "#   ##   Arch:          /usr/lib/sa/sadc\r\n",
      "#   ##   RHEL/CentOS:   /usr/lib64/sa/sadc\r\n",
      "#   sadc_path = \"/usr/lib/sa/sadc\" # required\r\n",
      "#   #\r\n",
      "#   #\r\n",
      "#   ## Path to the sadf command, if it is not in PATH\r\n",
      "#   # sadf_path = \"/usr/bin/sadf\"\r\n",
      "#   #\r\n",
      "#   #\r\n",
      "#   ## Activities is a list of activities, that are passed as argument to the\r\n",
      "#   ## sadc collector utility (e.g: DISK, SNMP etc...)\r\n",
      "#   ## The more activities that are added, the more data is collected.\r\n",
      "#   # activities = [\"DISK\"]\r\n",
      "#   #\r\n",
      "#   #\r\n",
      "#   ## Group metrics to measurements.\r\n",
      "#   ##\r\n",
      "#   ## If group is false each metric will be prefixed with a description\r\n",
      "#   ## and represents itself a measurement.\r\n",
      "#   ##\r\n",
      "#   ## If Group is true, corresponding metrics are grouped to a single measurement.\r\n",
      "#   # group = true\r\n",
      "#   #\r\n",
      "#   #\r\n",
      "#   ## Options for the sadf command. The values on the left represent the sadf\r\n",
      "#   ## options and the values on the right their description (which are used for\r\n",
      "#   ## grouping and prefixing metrics).\r\n",
      "#   ##\r\n",
      "#   ## Run 'sar -h' or 'man sar' to find out the supported options for your\r\n",
      "#   ## sysstat version.\r\n",
      "#   [inputs.sysstat.options]\r\n",
      "#     -C = \"cpu\"\r\n",
      "#     -B = \"paging\"\r\n",
      "#     -b = \"io\"\r\n",
      "#     -d = \"disk\"             # requires DISK activity\r\n",
      "#     \"-n ALL\" = \"network\"\r\n",
      "#     \"-P ALL\" = \"per_cpu\"\r\n",
      "#     -q = \"queue\"\r\n",
      "#     -R = \"mem\"\r\n",
      "#     -r = \"mem_util\"\r\n",
      "#     -S = \"swap_util\"\r\n",
      "#     -u = \"cpu_util\"\r\n",
      "#     -v = \"inode\"\r\n",
      "#     -W = \"swap\"\r\n",
      "#     -w = \"task\"\r\n",
      "#   #  -H = \"hugepages\"        # only available for newer linux distributions\r\n",
      "#   #  \"-I ALL\" = \"interrupts\" # requires INT activity\r\n",
      "#   #\r\n",
      "#   #\r\n",
      "#   ## Device tags can be used to add additional tags for devices.\r\n",
      "#   ## For example the configuration below adds a tag vg with value rootvg for\r\n",
      "#   ## all metrics with sda devices.\r\n",
      "#   # [[inputs.sysstat.device_tags.sda]]\r\n",
      "#   #  vg = \"rootvg\"\r\n",
      "\r\n",
      "\r\n",
      "# # Reads metrics from a Teamspeak 3 Server via ServerQuery\r\n",
      "# [[inputs.teamspeak]]\r\n",
      "#   ## Server address for Teamspeak 3 ServerQuery\r\n",
      "#   # server = \"127.0.0.1:10011\"\r\n",
      "#   ## Username for ServerQuery\r\n",
      "#   username = \"serverqueryuser\"\r\n",
      "#   ## Password for ServerQuery\r\n",
      "#   password = \"secret\"\r\n",
      "#   ## Array of virtual servers\r\n",
      "#   # virtual_servers = [1]\r\n",
      "\r\n",
      "\r\n",
      "# # Gather metrics from the Tomcat server status page.\r\n",
      "# [[inputs.tomcat]]\r\n",
      "#   ## URL of the Tomcat server status\r\n",
      "#   # url = \"http://127.0.0.1:8080/manager/status/all?XML=true\"\r\n",
      "#\r\n",
      "#   ## HTTP Basic Auth Credentials\r\n",
      "#   # username = \"tomcat\"\r\n",
      "#   # password = \"s3cret\"\r\n",
      "#\r\n",
      "#   ## Request timeout\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "\r\n",
      "\r\n",
      "# # Inserts sine and cosine waves for demonstration purposes\r\n",
      "# [[inputs.trig]]\r\n",
      "#   ## Set the amplitude\r\n",
      "#   amplitude = 10.0\r\n",
      "\r\n",
      "\r\n",
      "# # Read Twemproxy stats data\r\n",
      "# [[inputs.twemproxy]]\r\n",
      "#   ## Twemproxy stats address and port (no scheme)\r\n",
      "#   addr = \"localhost:22222\"\r\n",
      "#   ## Monitor pool name\r\n",
      "#   pools = [\"redis_pool\", \"mc_pool\"]\r\n",
      "\r\n",
      "\r\n",
      "# # A plugin to collect stats from the Unbound DNS resolver\r\n",
      "# [[inputs.unbound]]\r\n",
      "#   ## Address of server to connect to, read from unbound conf default, optionally ':port'\r\n",
      "#   ## Will lookup IP if given a hostname\r\n",
      "#   server = \"127.0.0.1:8953\"\r\n",
      "#\r\n",
      "#   ## If running as a restricted user you can prepend sudo for additional access:\r\n",
      "#   # use_sudo = false\r\n",
      "#\r\n",
      "#   ## The default location of the unbound-control binary can be overridden with:\r\n",
      "#   # binary = \"/usr/sbin/unbound-control\"\r\n",
      "#\r\n",
      "#   ## The default timeout of 1s can be overriden with:\r\n",
      "#   # timeout = \"1s\"\r\n",
      "#\r\n",
      "#   ## When set to true, thread metrics are tagged with the thread id.\r\n",
      "#   ##\r\n",
      "#   ## The default is false for backwards compatibility, and will be change to\r\n",
      "#   ## true in a future version.  It is recommended to set to true on new\r\n",
      "#   ## deployments.\r\n",
      "#   thread_as_tag = false\r\n",
      "\r\n",
      "\r\n",
      "# # A plugin to collect stats from Varnish HTTP Cache\r\n",
      "# [[inputs.varnish]]\r\n",
      "#   ## If running as a restricted user you can prepend sudo for additional access:\r\n",
      "#   #use_sudo = false\r\n",
      "#\r\n",
      "#   ## The default location of the varnishstat binary can be overridden with:\r\n",
      "#   binary = \"/usr/bin/varnishstat\"\r\n",
      "#\r\n",
      "#   ## By default, telegraf gather stats for 3 metric points.\r\n",
      "#   ## Setting stats will override the defaults shown below.\r\n",
      "#   ## Glob matching can be used, ie, stats = [\"MAIN.*\"]\r\n",
      "#   ## stats may also be set to [\"*\"], which will collect all stats\r\n",
      "#   stats = [\"MAIN.cache_hit\", \"MAIN.cache_miss\", \"MAIN.uptime\"]\r\n",
      "#\r\n",
      "#   ## Optional name for the varnish instance (or working directory) to query\r\n",
      "#   ## Usually appened after -n in varnish cli\r\n",
      "#   # instance_name = instanceName\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics of ZFS from arcstats, zfetchstats, vdev_cache_stats, and pools\r\n",
      "# [[inputs.zfs]]\r\n",
      "#   ## ZFS kstat path. Ignored on FreeBSD\r\n",
      "#   ## If not specified, then default is:\r\n",
      "#   # kstatPath = \"/proc/spl/kstat/zfs\"\r\n",
      "#\r\n",
      "#   ## By default, telegraf gather all zfs stats\r\n",
      "#   ## If not specified, then default is:\r\n",
      "#   # kstatMetrics = [\"arcstats\", \"zfetchstats\", \"vdev_cache_stats\"]\r\n",
      "#   ## For Linux, the default is:\r\n",
      "#   # kstatMetrics = [\"abdstats\", \"arcstats\", \"dnodestats\", \"dbufcachestats\",\r\n",
      "#   #   \"dmu_tx\", \"fm\", \"vdev_mirror_stats\", \"zfetchstats\", \"zil\"]\r\n",
      "#   ## By default, don't gather zpool stats\r\n",
      "#   # poolMetrics = false\r\n",
      "\r\n",
      "\r\n",
      "# # Reads 'mntr' stats from one or many zookeeper servers\r\n",
      "# [[inputs.zookeeper]]\r\n",
      "#   ## An array of address to gather stats about. Specify an ip or hostname\r\n",
      "#   ## with port. ie localhost:2181, 10.0.0.1:2181, etc.\r\n",
      "#\r\n",
      "#   ## If no servers are specified, then localhost is used as the host.\r\n",
      "#   ## If no port is specified, 2181 is used\r\n",
      "#   servers = [\":2181\"]\r\n",
      "#\r\n",
      "#   ## Timeout for metric collections from all servers.  Minimum timeout is \"1s\".\r\n",
      "#   # timeout = \"5s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # enable_tls = true\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## If false, skip chain & host verification\r\n",
      "#   # insecure_skip_verify = true\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "###############################################################################\r\n",
      "#                            SERVICE INPUT PLUGINS                            #\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "# # AMQP consumer plugin\r\n",
      "# [[inputs.amqp_consumer]]\r\n",
      "#   ## Broker to consume from.\r\n",
      "#   ##   deprecated in 1.7; use the brokers option\r\n",
      "#   # url = \"amqp://localhost:5672/influxdb\"\r\n",
      "#\r\n",
      "#   ## Brokers to consume from.  If multiple brokers are specified a random broker\r\n",
      "#   ## will be selected anytime a connection is established.  This can be\r\n",
      "#   ## helpful for load balancing when not using a dedicated load balancer.\r\n",
      "#   brokers = [\"amqp://localhost:5672/influxdb\"]\r\n",
      "#\r\n",
      "#   ## Authentication credentials for the PLAIN auth_method.\r\n",
      "#   # username = \"\"\r\n",
      "#   # password = \"\"\r\n",
      "#\r\n",
      "#   ## Exchange to declare and consume from.\r\n",
      "#   exchange = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## Exchange type; common types are \"direct\", \"fanout\", \"topic\", \"header\", \"x-consistent-hash\".\r\n",
      "#   # exchange_type = \"topic\"\r\n",
      "#\r\n",
      "#   ## If true, exchange will be passively declared.\r\n",
      "#   # exchange_passive = false\r\n",
      "#\r\n",
      "#   ## Exchange durability can be either \"transient\" or \"durable\".\r\n",
      "#   # exchange_durability = \"durable\"\r\n",
      "#\r\n",
      "#   ## Additional exchange arguments.\r\n",
      "#   # exchange_arguments = { }\r\n",
      "#   # exchange_arguments = {\"hash_propery\" = \"timestamp\"}\r\n",
      "#\r\n",
      "#   ## AMQP queue name\r\n",
      "#   queue = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## Binding Key\r\n",
      "#   binding_key = \"#\"\r\n",
      "#\r\n",
      "#   ## Maximum number of messages server should give to the worker.\r\n",
      "#   # prefetch_count = 50\r\n",
      "#\r\n",
      "#   ## Auth method. PLAIN and EXTERNAL are supported\r\n",
      "#   ## Using EXTERNAL requires enabling the rabbitmq_auth_mechanism_ssl plugin as\r\n",
      "#   ## described here: https://www.rabbitmq.com/plugins.html\r\n",
      "#   # auth_method = \"PLAIN\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read Cassandra metrics through Jolokia\r\n",
      "# [[inputs.cassandra]]\r\n",
      "#   ## DEPRECATED: The cassandra plugin has been deprecated.  Please use the\r\n",
      "#   ## jolokia2 plugin instead.\r\n",
      "#   ##\r\n",
      "#   ## see https://github.com/influxdata/telegraf/tree/master/plugins/inputs/jolokia2\r\n",
      "#\r\n",
      "#   context = \"/jolokia/read\"\r\n",
      "#   ## List of cassandra servers exposing jolokia read service\r\n",
      "#   servers = [\"myuser:mypassword@10.10.10.1:8778\",\"10.10.10.2:8778\",\":8778\"]\r\n",
      "#   ## List of metrics collected on above servers\r\n",
      "#   ## Each metric consists of a jmx path.\r\n",
      "#   ## This will collect all heap memory usage metrics from the jvm and\r\n",
      "#   ## ReadLatency metrics for all keyspaces and tables.\r\n",
      "#   ## \"type=Table\" in the query works with Cassandra3.0. Older versions might\r\n",
      "#   ## need to use \"type=ColumnFamily\"\r\n",
      "#   metrics  = [\r\n",
      "#     \"/java.lang:type=Memory/HeapMemoryUsage\",\r\n",
      "#     \"/org.apache.cassandra.metrics:type=Table,keyspace=*,scope=*,name=ReadLatency\"\r\n",
      "#   ]\r\n",
      "\r\n",
      "\r\n",
      "# # Influx HTTP write listener\r\n",
      "# [[inputs.http_listener]]\r\n",
      "#   ## Address and port to host HTTP listener on\r\n",
      "#   service_address = \":8186\"\r\n",
      "#\r\n",
      "#   ## maximum duration before timing out read of the request\r\n",
      "#   read_timeout = \"10s\"\r\n",
      "#   ## maximum duration before timing out write of the response\r\n",
      "#   write_timeout = \"10s\"\r\n",
      "#\r\n",
      "#   ## Maximum allowed http request body size in bytes.\r\n",
      "#   ## 0 means to use the default of 536,870,912 bytes (500 mebibytes)\r\n",
      "#   max_body_size = 0\r\n",
      "#\r\n",
      "#   ## Maximum line size allowed to be sent in bytes.\r\n",
      "#   ## 0 means to use the default of 65536 bytes (64 kibibytes)\r\n",
      "#   max_line_size = 0\r\n",
      "#\r\n",
      "#   ## Set one or more allowed client CA certificate file names to\r\n",
      "#   ## enable mutually authenticated TLS connections\r\n",
      "#   tls_allowed_cacerts = [\"/etc/telegraf/clientca.pem\"]\r\n",
      "#\r\n",
      "#   ## Add service certificate and key\r\n",
      "#   tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#\r\n",
      "#   ## Optional username and password to accept for HTTP basic authentication.\r\n",
      "#   ## You probably want to make sure you have TLS configured above for this.\r\n",
      "#   # basic_username = \"foobar\"\r\n",
      "#   # basic_password = \"barfoo\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read JTI OpenConfig Telemetry from listed sensors\r\n",
      "# [[inputs.jti_openconfig_telemetry]]\r\n",
      "#   ## List of device addresses to collect telemetry from\r\n",
      "#   servers = [\"localhost:1883\"]\r\n",
      "#\r\n",
      "#   ## Authentication details. Username and password are must if device expects\r\n",
      "#   ## authentication. Client ID must be unique when connecting from multiple instances\r\n",
      "#   ## of telegraf to the same device\r\n",
      "#   username = \"user\"\r\n",
      "#   password = \"pass\"\r\n",
      "#   client_id = \"telegraf\"\r\n",
      "#\r\n",
      "#   ## Frequency to get data\r\n",
      "#   sample_frequency = \"1000ms\"\r\n",
      "#\r\n",
      "#   ## Sensors to subscribe for\r\n",
      "#   ## A identifier for each sensor can be provided in path by separating with space\r\n",
      "#   ## Else sensor path will be used as identifier\r\n",
      "#   ## When identifier is used, we can provide a list of space separated sensors.\r\n",
      "#   ## A single subscription will be created with all these sensors and data will\r\n",
      "#   ## be saved to measurement with this identifier name\r\n",
      "#   sensors = [\r\n",
      "#    \"/interfaces/\",\r\n",
      "#    \"collection /components/ /lldp\",\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   ## We allow specifying sensor group level reporting rate. To do this, specify the\r\n",
      "#   ## reporting rate in Duration at the beginning of sensor paths / collection\r\n",
      "#   ## name. For entries without reporting rate, we use configured sample frequency\r\n",
      "#   sensors = [\r\n",
      "#    \"1000ms customReporting /interfaces /lldp\",\r\n",
      "#    \"2000ms collection /components\",\r\n",
      "#    \"/interfaces\",\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   ## x509 Certificate to use with TLS connection. If it is not provided, an insecure\r\n",
      "#   ## channel will be opened with server\r\n",
      "#   ssl_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#\r\n",
      "#   ## Delay between retry attempts of failed RPC calls or streams. Defaults to 1000ms.\r\n",
      "#   ## Failed streams/calls will not be retried if 0 is provided\r\n",
      "#   retry_delay = \"1000ms\"\r\n",
      "#\r\n",
      "#   ## To treat all string values as tags, set this to true\r\n",
      "#   str_as_tags = false\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from Kafka topic(s)\r\n",
      "# [[inputs.kafka_consumer]]\r\n",
      "#   ## kafka servers\r\n",
      "#   brokers = [\"localhost:9092\"]\r\n",
      "#   ## topic(s) to consume\r\n",
      "#   topics = [\"telegraf\"]\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Optional SASL Config\r\n",
      "#   # sasl_username = \"kafka\"\r\n",
      "#   # sasl_password = \"secret\"\r\n",
      "#\r\n",
      "#   ## the name of the consumer group\r\n",
      "#   consumer_group = \"telegraf_metrics_consumers\"\r\n",
      "#   ## Offset (must be either \"oldest\" or \"newest\")\r\n",
      "#   offset = \"oldest\"\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "#\r\n",
      "#   ## Maximum length of a message to consume, in bytes (default 0/unlimited);\r\n",
      "#   ## larger messages are dropped\r\n",
      "#   max_message_len = 65536\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from Kafka topic(s)\r\n",
      "# [[inputs.kafka_consumer_legacy]]\r\n",
      "#   ## topic(s) to consume\r\n",
      "#   topics = [\"telegraf\"]\r\n",
      "#   ## an array of Zookeeper connection strings\r\n",
      "#   zookeeper_peers = [\"localhost:2181\"]\r\n",
      "#   ## Zookeeper Chroot\r\n",
      "#   zookeeper_chroot = \"\"\r\n",
      "#   ## the name of the consumer group\r\n",
      "#   consumer_group = \"telegraf_metrics_consumers\"\r\n",
      "#   ## Offset (must be either \"oldest\" or \"newest\")\r\n",
      "#   offset = \"oldest\"\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "#\r\n",
      "#   ## Maximum length of a message to consume, in bytes (default 0/unlimited);\r\n",
      "#   ## larger messages are dropped\r\n",
      "#   max_message_len = 65536\r\n",
      "\r\n",
      "\r\n",
      "# # Stream and parse log file(s).\r\n",
      "# [[inputs.logparser]]\r\n",
      "#   ## Log files to parse.\r\n",
      "#   ## These accept standard unix glob matching rules, but with the addition of\r\n",
      "#   ## ** as a \"super asterisk\". ie:\r\n",
      "#   ##   /var/log/**.log     -> recursively find all .log files in /var/log\r\n",
      "#   ##   /var/log/*/*.log    -> find all .log files with a parent dir in /var/log\r\n",
      "#   ##   /var/log/apache.log -> only tail the apache log file\r\n",
      "#   files = [\"/var/log/apache/access.log\"]\r\n",
      "#\r\n",
      "#   ## Read files that currently exist from the beginning. Files that are created\r\n",
      "#   ## while telegraf is running (and that match the \"files\" globs) will always\r\n",
      "#   ## be read from the beginning.\r\n",
      "#   from_beginning = false\r\n",
      "#\r\n",
      "#   ## Method used to watch for file updates.  Can be either \"inotify\" or \"poll\".\r\n",
      "#   # watch_method = \"inotify\"\r\n",
      "#\r\n",
      "#   ## Parse logstash-style \"grok\" patterns:\r\n",
      "#   [inputs.logparser.grok]\r\n",
      "#     ## This is a list of patterns to check the given log file(s) for.\r\n",
      "#     ## Note that adding patterns here increases processing time. The most\r\n",
      "#     ## efficient configuration is to have one pattern per logparser.\r\n",
      "#     ## Other common built-in patterns are:\r\n",
      "#     ##   %{COMMON_LOG_FORMAT}   (plain apache & nginx access logs)\r\n",
      "#     ##   %{COMBINED_LOG_FORMAT} (access logs + referrer & agent)\r\n",
      "#     patterns = [\"%{COMBINED_LOG_FORMAT}\"]\r\n",
      "#\r\n",
      "#     ## Name of the outputted measurement name.\r\n",
      "#     measurement = \"apache_access_log\"\r\n",
      "#\r\n",
      "#     ## Full path(s) to custom pattern files.\r\n",
      "#     custom_pattern_files = []\r\n",
      "#\r\n",
      "#     ## Custom patterns can also be defined here. Put one pattern per line.\r\n",
      "#     custom_patterns = '''\r\n",
      "#\r\n",
      "#     ## Timezone allows you to provide an override for timestamps that\r\n",
      "#     ## don't already include an offset\r\n",
      "#     ## e.g. 04/06/2016 12:41:45 data one two 5.43Âµs\r\n",
      "#     ##\r\n",
      "#     ## Default: \"\" which renders UTC\r\n",
      "#     ## Options are as follows:\r\n",
      "#     ##   1. Local             -- interpret based on machine localtime\r\n",
      "#     ##   2. \"Canada/Eastern\"  -- Unix TZ values like those found in https://en.wikipedia.org/wiki/List_of_tz_database_time_zones\r\n",
      "#     ##   3. UTC               -- or blank/unspecified, will return timestamp in UTC\r\n",
      "#     timezone = \"Canada/Eastern\"\r\n",
      "#     '''\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from MQTT topic(s)\r\n",
      "# [[inputs.mqtt_consumer]]\r\n",
      "#   ## MQTT broker URLs to be used. The format should be scheme://host:port,\r\n",
      "#   ## schema can be tcp, ssl, or ws.\r\n",
      "#   servers = [\"tcp://localhost:1883\"]\r\n",
      "#\r\n",
      "#   ## MQTT QoS, must be 0, 1, or 2\r\n",
      "#   qos = 0\r\n",
      "#   ## Connection timeout for initial connection in seconds\r\n",
      "#   connection_timeout = \"30s\"\r\n",
      "#\r\n",
      "#   ## Topics to subscribe to\r\n",
      "#   topics = [\r\n",
      "#     \"telegraf/host01/cpu\",\r\n",
      "#     \"telegraf/+/mem\",\r\n",
      "#     \"sensors/#\",\r\n",
      "#   ]\r\n",
      "#\r\n",
      "#   # if true, messages that can't be delivered while the subscriber is offline\r\n",
      "#   # will be delivered when it comes back (such as on service restart).\r\n",
      "#   # NOTE: if true, client_id MUST be set\r\n",
      "#   persistent_session = false\r\n",
      "#   # If empty, a random client ID will be generated.\r\n",
      "#   client_id = \"\"\r\n",
      "#\r\n",
      "#   ## username and password to connect MQTT server.\r\n",
      "#   # username = \"telegraf\"\r\n",
      "#   # password = \"metricsmetricsmetricsmetrics\"\r\n",
      "#\r\n",
      "#   ## Optional TLS Config\r\n",
      "#   # tls_ca = \"/etc/telegraf/ca.pem\"\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Use TLS but skip chain & host verification\r\n",
      "#   # insecure_skip_verify = false\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from NATS subject(s)\r\n",
      "# [[inputs.nats_consumer]]\r\n",
      "#   ## urls of NATS servers\r\n",
      "#   # servers = [\"nats://localhost:4222\"]\r\n",
      "#   ## Use Transport Layer Security\r\n",
      "#   # secure = false\r\n",
      "#   ## subject(s) to consume\r\n",
      "#   # subjects = [\"telegraf\"]\r\n",
      "#   ## name a queue group\r\n",
      "#   # queue_group = \"telegraf_consumers\"\r\n",
      "#\r\n",
      "#   ## Sets the limits for pending msgs and bytes for each subscription\r\n",
      "#   ## These shouldn't need to be adjusted except in very high throughput scenarios\r\n",
      "#   # pending_message_limit = 65536\r\n",
      "#   # pending_bytes_limit = 67108864\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read NSQ topic for metrics.\r\n",
      "# [[inputs.nsq_consumer]]\r\n",
      "#   ## Server option still works but is deprecated, we just prepend it to the nsqd array.\r\n",
      "#   # server = \"localhost:4150\"\r\n",
      "#   ## An array representing the NSQD TCP HTTP Endpoints\r\n",
      "#   nsqd = [\"localhost:4150\"]\r\n",
      "#   ## An array representing the NSQLookupd HTTP Endpoints\r\n",
      "#   nsqlookupd = [\"localhost:4161\"]\r\n",
      "#   topic = \"telegraf\"\r\n",
      "#   channel = \"consumer\"\r\n",
      "#   max_in_flight = 100\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many postgresql servers\r\n",
      "# [[inputs.postgresql]]\r\n",
      "#   ## specify address via a url matching:\r\n",
      "#   ##   postgres://[pqgotest[:password]]@localhost[/dbname]\\\r\n",
      "#   ##       ?sslmode=[disable|verify-ca|verify-full]\r\n",
      "#   ## or a simple string:\r\n",
      "#   ##   host=localhost user=pqotest password=... sslmode=... dbname=app_production\r\n",
      "#   ##\r\n",
      "#   ## All connection parameters are optional.\r\n",
      "#   ##\r\n",
      "#   ## Without the dbname parameter, the driver will default to a database\r\n",
      "#   ## with the same name as the user. This dbname is just for instantiating a\r\n",
      "#   ## connection with the server and doesn't restrict the databases we are trying\r\n",
      "#   ## to grab metrics for.\r\n",
      "#   ##\r\n",
      "#   address = \"host=localhost user=postgres sslmode=disable\"\r\n",
      "#   ## A custom name for the database that will be used as the \"server\" tag in the\r\n",
      "#   ## measurement output. If not specified, a default one generated from\r\n",
      "#   ## the connection address is used.\r\n",
      "#   # outputaddress = \"db01\"\r\n",
      "#\r\n",
      "#   ## connection configuration.\r\n",
      "#   ## maxlifetime - specify the maximum lifetime of a connection.\r\n",
      "#   ## default is forever (0s)\r\n",
      "#   max_lifetime = \"0s\"\r\n",
      "#\r\n",
      "#   ## A  list of databases to explicitly ignore.  If not specified, metrics for all\r\n",
      "#   ## databases are gathered.  Do NOT use with the 'databases' option.\r\n",
      "#   # ignored_databases = [\"postgres\", \"template0\", \"template1\"]\r\n",
      "#\r\n",
      "#   ## A list of databases to pull metrics about. If not specified, metrics for all\r\n",
      "#   ## databases are gathered.  Do NOT use with the 'ignored_databases' option.\r\n",
      "#   # databases = [\"app_production\", \"testing\"]\r\n",
      "\r\n",
      "\r\n",
      "# # Read metrics from one or many postgresql servers\r\n",
      "# [[inputs.postgresql_extensible]]\r\n",
      "#   ## specify address via a url matching:\r\n",
      "#   ##   postgres://[pqgotest[:password]]@localhost[/dbname]\\\r\n",
      "#   ##       ?sslmode=[disable|verify-ca|verify-full]\r\n",
      "#   ## or a simple string:\r\n",
      "#   ##   host=localhost user=pqotest password=... sslmode=... dbname=app_production\r\n",
      "#   #\r\n",
      "#   ## All connection parameters are optional.  #\r\n",
      "#   ## Without the dbname parameter, the driver will default to a database\r\n",
      "#   ## with the same name as the user. This dbname is just for instantiating a\r\n",
      "#   ## connection with the server and doesn't restrict the databases we are trying\r\n",
      "#   ## to grab metrics for.\r\n",
      "#   #\r\n",
      "#   address = \"host=localhost user=postgres sslmode=disable\"\r\n",
      "#\r\n",
      "#   ## connection configuration.\r\n",
      "#   ## maxlifetime - specify the maximum lifetime of a connection.\r\n",
      "#   ## default is forever (0s)\r\n",
      "#   max_lifetime = \"0s\"\r\n",
      "#\r\n",
      "#   ## A list of databases to pull metrics about. If not specified, metrics for all\r\n",
      "#   ## databases are gathered.\r\n",
      "#   ## databases = [\"app_production\", \"testing\"]\r\n",
      "#   #\r\n",
      "#   ## A custom name for the database that will be used as the \"server\" tag in the\r\n",
      "#   ## measurement output. If not specified, a default one generated from\r\n",
      "#   ## the connection address is used.\r\n",
      "#   # outputaddress = \"db01\"\r\n",
      "#   #\r\n",
      "#   ## Define the toml config where the sql queries are stored\r\n",
      "#   ## New queries can be added, if the withdbname is set to true and there is no\r\n",
      "#   ## databases defined in the 'databases field', the sql query is ended by a\r\n",
      "#   ## 'is not null' in order to make the query succeed.\r\n",
      "#   ## Example :\r\n",
      "#   ## The sqlquery : \"SELECT * FROM pg_stat_database where datname\" become\r\n",
      "#   ## \"SELECT * FROM pg_stat_database where datname IN ('postgres', 'pgbench')\"\r\n",
      "#   ## because the databases variable was set to ['postgres', 'pgbench' ] and the\r\n",
      "#   ## withdbname was true. Be careful that if the withdbname is set to false you\r\n",
      "#   ## don't have to define the where clause (aka with the dbname) the tagvalue\r\n",
      "#   ## field is used to define custom tags (separated by commas)\r\n",
      "#   ## The optional \"measurement\" value can be used to override the default\r\n",
      "#   ## output measurement name (\"postgresql\").\r\n",
      "#   #\r\n",
      "#   ## Structure :\r\n",
      "#   ## [[inputs.postgresql_extensible.query]]\r\n",
      "#   ##   sqlquery string\r\n",
      "#   ##   version string\r\n",
      "#   ##   withdbname boolean\r\n",
      "#   ##   tagvalue string (comma separated)\r\n",
      "#   ##   measurement string\r\n",
      "#   [[inputs.postgresql_extensible.query]]\r\n",
      "#     sqlquery=\"SELECT * FROM pg_stat_database\"\r\n",
      "#     version=901\r\n",
      "#     withdbname=false\r\n",
      "#     tagvalue=\"\"\r\n",
      "#     measurement=\"\"\r\n",
      "#   [[inputs.postgresql_extensible.query]]\r\n",
      "#     sqlquery=\"SELECT * FROM pg_stat_bgwriter\"\r\n",
      "#     version=901\r\n",
      "#     withdbname=false\r\n",
      "#     tagvalue=\"postgresql.stats\"\r\n",
      "\r\n",
      "\r\n",
      "# # Generic socket listener capable of handling multiple socket types.\r\n",
      "# [[inputs.socket_listener]]\r\n",
      "#   ## URL to listen on\r\n",
      "#   # service_address = \"tcp://:8094\"\r\n",
      "#   # service_address = \"tcp://127.0.0.1:http\"\r\n",
      "#   # service_address = \"tcp4://:8094\"\r\n",
      "#   # service_address = \"tcp6://:8094\"\r\n",
      "#   # service_address = \"tcp6://[2001:db8::1]:8094\"\r\n",
      "#   # service_address = \"udp://:8094\"\r\n",
      "#   # service_address = \"udp4://:8094\"\r\n",
      "#   # service_address = \"udp6://:8094\"\r\n",
      "#   # service_address = \"unix:///tmp/telegraf.sock\"\r\n",
      "#   # service_address = \"unixgram:///tmp/telegraf.sock\"\r\n",
      "#\r\n",
      "#   ## Maximum number of concurrent connections.\r\n",
      "#   ## Only applies to stream sockets (e.g. TCP).\r\n",
      "#   ## 0 (default) is unlimited.\r\n",
      "#   # max_connections = 1024\r\n",
      "#\r\n",
      "#   ## Read timeout.\r\n",
      "#   ## Only applies to stream sockets (e.g. TCP).\r\n",
      "#   ## 0 (default) is unlimited.\r\n",
      "#   # read_timeout = \"30s\"\r\n",
      "#\r\n",
      "#   ## Optional TLS configuration.\r\n",
      "#   ## Only applies to stream sockets (e.g. TCP).\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key  = \"/etc/telegraf/key.pem\"\r\n",
      "#   ## Enables client authentication if set.\r\n",
      "#   # tls_allowed_cacerts = [\"/etc/telegraf/clientca.pem\"]\r\n",
      "#\r\n",
      "#   ## Maximum socket buffer size in bytes.\r\n",
      "#   ## For stream sockets, once the buffer fills up, the sender will start backing up.\r\n",
      "#   ## For datagram sockets, once the buffer fills up, metrics will start dropping.\r\n",
      "#   ## Defaults to the OS default.\r\n",
      "#   # read_buffer_size = 65535\r\n",
      "#\r\n",
      "#   ## Period between keep alive probes.\r\n",
      "#   ## Only applies to TCP sockets.\r\n",
      "#   ## 0 disables keep alive probes.\r\n",
      "#   ## Defaults to the OS configuration.\r\n",
      "#   # keep_alive_period = \"5m\"\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   # data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Statsd UDP/TCP Server\r\n",
      "# [[inputs.statsd]]\r\n",
      "#   ## Protocol, must be \"tcp\", \"udp\", \"udp4\" or \"udp6\" (default=udp)\r\n",
      "#   protocol = \"udp\"\r\n",
      "#\r\n",
      "#   ## MaxTCPConnection - applicable when protocol is set to tcp (default=250)\r\n",
      "#   max_tcp_connections = 250\r\n",
      "#\r\n",
      "#   ## Enable TCP keep alive probes (default=false)\r\n",
      "#   tcp_keep_alive = false\r\n",
      "#\r\n",
      "#   ## Specifies the keep-alive period for an active network connection.\r\n",
      "#   ## Only applies to TCP sockets and will be ignored if tcp_keep_alive is false.\r\n",
      "#   ## Defaults to the OS configuration.\r\n",
      "#   # tcp_keep_alive_period = \"2h\"\r\n",
      "#\r\n",
      "#   ## Address and port to host UDP listener on\r\n",
      "#   service_address = \":8125\"\r\n",
      "#\r\n",
      "#   ## The following configuration options control when telegraf clears it's cache\r\n",
      "#   ## of previous values. If set to false, then telegraf will only clear it's\r\n",
      "#   ## cache when the daemon is restarted.\r\n",
      "#   ## Reset gauges every interval (default=true)\r\n",
      "#   delete_gauges = true\r\n",
      "#   ## Reset counters every interval (default=true)\r\n",
      "#   delete_counters = true\r\n",
      "#   ## Reset sets every interval (default=true)\r\n",
      "#   delete_sets = true\r\n",
      "#   ## Reset timings & histograms every interval (default=true)\r\n",
      "#   delete_timings = true\r\n",
      "#\r\n",
      "#   ## Percentiles to calculate for timing & histogram stats\r\n",
      "#   percentiles = [90]\r\n",
      "#\r\n",
      "#   ## separator to use between elements of a statsd metric\r\n",
      "#   metric_separator = \"_\"\r\n",
      "#\r\n",
      "#   ## Parses tags in the datadog statsd format\r\n",
      "#   ## http://docs.datadoghq.com/guides/dogstatsd/\r\n",
      "#   parse_data_dog_tags = false\r\n",
      "#\r\n",
      "#   ## Statsd data translation templates, more info can be read here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md#graphite\r\n",
      "#   # templates = [\r\n",
      "#   #     \"cpu.* measurement*\"\r\n",
      "#   # ]\r\n",
      "#\r\n",
      "#   ## Number of UDP messages allowed to queue up, once filled,\r\n",
      "#   ## the statsd server will start dropping packets\r\n",
      "#   allowed_pending_messages = 10000\r\n",
      "#\r\n",
      "#   ## Number of timing/histogram values to track per-measurement in the\r\n",
      "#   ## calculation of percentiles. Raising this limit increases the accuracy\r\n",
      "#   ## of percentiles but also increases the memory usage and cpu time.\r\n",
      "#   percentile_limit = 1000\r\n",
      "\r\n",
      "\r\n",
      "# # Accepts syslog messages per RFC5425\r\n",
      "# [[inputs.syslog]]\r\n",
      "#   ## Specify an ip or hostname with port - eg., tcp://localhost:6514, tcp://10.0.0.1:6514\r\n",
      "#   ## Protocol, address and port to host the syslog receiver.\r\n",
      "#   ## If no host is specified, then localhost is used.\r\n",
      "#   ## If no port is specified, 6514 is used (RFC5425#section-4.1).\r\n",
      "#   server = \"tcp://:6514\"\r\n",
      "#\r\n",
      "#   ## TLS Config\r\n",
      "#   # tls_allowed_cacerts = [\"/etc/telegraf/ca.pem\"]\r\n",
      "#   # tls_cert = \"/etc/telegraf/cert.pem\"\r\n",
      "#   # tls_key = \"/etc/telegraf/key.pem\"\r\n",
      "#\r\n",
      "#   ## Period between keep alive probes.\r\n",
      "#   ## 0 disables keep alive probes.\r\n",
      "#   ## Defaults to the OS configuration.\r\n",
      "#   ## Only applies to stream sockets (e.g. TCP).\r\n",
      "#   # keep_alive_period = \"5m\"\r\n",
      "#\r\n",
      "#   ## Maximum number of concurrent connections (default = 0).\r\n",
      "#   ## 0 means unlimited.\r\n",
      "#   ## Only applies to stream sockets (e.g. TCP).\r\n",
      "#   # max_connections = 1024\r\n",
      "#\r\n",
      "#   ## Read timeout (default = 500ms).\r\n",
      "#   ## 0 means unlimited.\r\n",
      "#   # read_timeout = 500ms\r\n",
      "#\r\n",
      "#   ## Whether to parse in best effort mode or not (default = false).\r\n",
      "#   ## By default best effort parsing is off.\r\n",
      "#   # best_effort = false\r\n",
      "#\r\n",
      "#   ## Character to prepend to SD-PARAMs (default = \"_\").\r\n",
      "#   ## A syslog message can contain multiple parameters and multiple identifiers within structured data section.\r\n",
      "#   ## Eg., [id1 name1=\"val1\" name2=\"val2\"][id2 name1=\"val1\" nameA=\"valA\"]\r\n",
      "#   ## For each combination a field is created.\r\n",
      "#   ## Its name is created concatenating identifier, sdparam_separator, and parameter name.\r\n",
      "#   # sdparam_separator = \"_\"\r\n",
      "\r\n",
      "\r\n",
      "# # Stream a log file, like the tail -f command\r\n",
      "# [[inputs.tail]]\r\n",
      "#   ## files to tail.\r\n",
      "#   ## These accept standard unix glob matching rules, but with the addition of\r\n",
      "#   ## ** as a \"super asterisk\". ie:\r\n",
      "#   ##   \"/var/log/**.log\"  -> recursively find all .log files in /var/log\r\n",
      "#   ##   \"/var/log/*/*.log\" -> find all .log files with a parent dir in /var/log\r\n",
      "#   ##   \"/var/log/apache.log\" -> just tail the apache log file\r\n",
      "#   ##\r\n",
      "#   ## See https://github.com/gobwas/glob for more examples\r\n",
      "#   ##\r\n",
      "#   files = [\"/var/mymetrics.out\"]\r\n",
      "#   ## Read file from beginning.\r\n",
      "#   from_beginning = false\r\n",
      "#   ## Whether file is a named pipe\r\n",
      "#   pipe = false\r\n",
      "#\r\n",
      "#   ## Method used to watch for file updates.  Can be either \"inotify\" or \"poll\".\r\n",
      "#   # watch_method = \"inotify\"\r\n",
      "#\r\n",
      "#   ## Data format to consume.\r\n",
      "#   ## Each data format has its own unique set of configuration options, read\r\n",
      "#   ## more about them here:\r\n",
      "#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\r\n",
      "#   data_format = \"influx\"\r\n",
      "\r\n",
      "\r\n",
      "# # Generic TCP listener\r\n",
      "# [[inputs.tcp_listener]]\r\n",
      "#   # DEPRECATED: the TCP listener plugin has been deprecated in favor of the\r\n",
      "#   # socket_listener plugin\r\n",
      "#   # see https://github.com/influxdata/telegraf/tree/master/plugins/inputs/socket_listener\r\n",
      "\r\n",
      "\r\n",
      "# # Generic UDP listener\r\n",
      "# [[inputs.udp_listener]]\r\n",
      "#   # DEPRECATED: the TCP listener plugin has been deprecated in favor of the\r\n",
      "#   # socket_listener plugin\r\n",
      "#   # see https://github.com/influxdata/telegraf/tree/master/plugins/inputs/socket_listener\r\n",
      "\r\n",
      "\r\n",
      "# # A Webhooks Event collector\r\n",
      "# [[inputs.webhooks]]\r\n",
      "#   ## Address and port to host Webhook listener on\r\n",
      "#   service_address = \":1619\"\r\n",
      "#\r\n",
      "#   [inputs.webhooks.filestack]\r\n",
      "#     path = \"/filestack\"\r\n",
      "#\r\n",
      "#   [inputs.webhooks.github]\r\n",
      "#     path = \"/github\"\r\n",
      "#     # secret = \"\"\r\n",
      "#\r\n",
      "#   [inputs.webhooks.mandrill]\r\n",
      "#     path = \"/mandrill\"\r\n",
      "#\r\n",
      "#   [inputs.webhooks.rollbar]\r\n",
      "#     path = \"/rollbar\"\r\n",
      "#\r\n",
      "#   [inputs.webhooks.papertrail]\r\n",
      "#     path = \"/papertrail\"\r\n",
      "#\r\n",
      "#   [inputs.webhooks.particle]\r\n",
      "#     path = \"/particle\"\r\n",
      "\r\n",
      "\r\n",
      "# # This plugin implements the Zipkin http server to gather trace and timing data needed to troubleshoot latency problems in microservice architectures.\r\n",
      "# [[inputs.zipkin]]\r\n",
      "#   # path = \"/api/v1/spans\" # URL path for span data\r\n",
      "#   # port = 9411            # Port on which Telegraf listens\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!docker exec -it influx-cluster-1 cat /etc/telegraf/telegraf.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Background processes not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-35b13df1cbf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#start telegraf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'docker exec -it influx-cluster-1 nohup telegraf --config /etc/telegraf/telegraf.config &'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;31m# os.system() or use ip.system=ip.system_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m             \u001b[0;31m# if they really want a background process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Background processes not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m         \u001b[0;31m# we explicitly do NOT return the subprocess status code, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Background processes not supported."
     ]
    }
   ],
   "source": [
    "#start telegraf\n",
    "!docker exec -it influx-cluster-1 nohup telegraf --config /etc/telegraf/telegraf.conf &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: measurements\r\n",
      "name\r\n",
      "----\r\n",
      "cpu\r\n",
      "disk\r\n",
      "diskio\r\n",
      "kernel\r\n",
      "mem\r\n",
      "processes\r\n",
      "swap\r\n",
      "system\r\n"
     ]
    }
   ],
   "source": [
    "!docker exec -it influx-cluster-1 influx -database 'telegraf' -execute 'show measurements'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
